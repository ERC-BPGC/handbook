{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The ERC Handbook","text":"<p>Welcome!</p> <p>The ERC Handbook is an extensive compilation of information and resources for everything robotics made by the Electronics and Robotics Club, BITS Goa.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":"<p>Full Changelog</p> <p>Implemented enhancements:</p> <ul> <li>Make Contribution Guidelines #5</li> </ul> <p>Fixed bugs:</p> <ul> <li>Development boards/arduino images cannot be displayed #28</li> </ul> <p>Closed issues:</p> <ul> <li>Changelog Test Issue #1 #55</li> <li>Add introductions to each sections #50</li> <li>Fix Changelog #49</li> <li>Fix image rendering problem in Control Theory #48</li> <li>fix images and equation in kinematics and dynamics section #37</li> <li>Add a section about STM \\(ARM\\) programming #25</li> <li>Restructure the contents related to ROS #22</li> <li>Restructure navigation sub-section  #15</li> <li>Add colcon under catkin #14</li> <li>Website build error #9</li> <li>Arrange the subtopics of automation, electronics and mechanics in a logical order #8</li> <li>Fix the security dependency issue #6</li> <li>Add a suitable picture for the home page #4</li> <li>Create initial subsections using the Summer Assignment resources section #3</li> <li>Remove all initial metadata and add title has ERC handbook #2</li> <li>Move frontpage to documentation #1</li> </ul> <p>Merged pull requests:</p> <ul> <li>added mechanical handbook section #75 (akagam1)</li> <li>Update mkdocs.yml #74 (Adonnes15)</li> <li>Rename Robot Description.md to Robot_Description.md #73 (Adonnes15)</li> <li>Rename Robot Description.md to Robot_Description.md #72 (Adonnes15)</li> <li>Update Robot Description.md #71 (Adonnes15)</li> <li>Added Sampling Based Path Planning Files #68 (ajaykrishna1878)</li> <li>Added Wifi-Module #65 (tanaypatni03)</li> <li>[21/09/21] Added Page for ESP 32  #64 (laukik29)</li> <li>[19/09/21] Added section Motors in Electronics, added a page on Servo Motor to Motors  #63 (Spindrift66)</li> <li>[15/09/21] Added page Pyboard-MicroPython to development boards in Electronics #62 (shyampoduval)</li> <li>[15/09/21] Added section Sensors in Electronics, added a page on Lidar to Sensors   #61 (TheRandomizer7)</li> <li>[02/09/21] Template markdown added #60 (Ashutosh781)</li> <li>[02/09/2021] Added content to introduction pages #59 (pranavgo)</li> <li>[02/02/2021] Revert \u201c[02/09/2021] Added content in introduction pages\u201d #58 (pranavgo)</li> <li>[02/09/2021] Added content in introduction pages #57 (pranavgo)</li> <li>[25/05/2021] Changelog Test PR # 1 #56 (veds12)</li> <li>[08/05/21] Fixed a typo in ROS.md #54 (Satyam0988)</li> <li>[12/01/2021] Roadmap for Robotics #53 (Ashutosh781)</li> <li>[05/01/2021] Images Fixed #52 (Ashutosh781)</li> <li>[05/01/2021] Image issue in control theory fixed #51 (Ashutosh781)</li> <li>[28/12/20] Added \u2018RoboticsKnowledgeBase\u2019 in \u2018Miscellaneous Resources\u2019 section  #47 (adbidwai)</li> <li>[27/12/2020] Added list of MOOCs #46 (veds12)</li> <li>[25/11/2020] Added References in Arduino #45 (Ashutosh781)</li> <li>[31/10/2020] Added Drive Mechanism #44 (Ashutosh781)</li> <li>[25/10/2020] Added a section about STM32  #43 (adbidwai)</li> <li>[25/10/20] added control theory #41 (pranavgo)</li> <li>[25/09/2020]Added STDR Simulator #40 (SuhrudhSarathy)</li> <li>[01/09/2020] Fixed image and math issues #39 (pranavgo)</li> <li>[31/08/2020] Added Dynamics and Kinematics #36 (pranavgo)</li> <li>[30/08/2020] Added Gears.md #31 (Ashutosh781)</li> <li>added breadboard.md, attr_list for image resizing #29 (enceladus2000)</li> <li>[16/08/2020]Added Arduino section under Dev Boards #27 (Ashutosh781)</li> <li>[09/08/2020] Added miscellaneous resources #26 (hardesh)</li> <li>[31/08/2020] Added PathPlanning, A*, Dijkstra\u2019s, RRT #24 (SuhrudhSarathy)</li> <li>[04/08/20] Added information about ROS Parameters #21 (adbidwai)</li> </ul> <p>* This Changelog was automatically generated by github_changelog_generator</p>"},{"location":"about/","title":"About Us","text":"<p>The Electronics and Robotics Club (ERC) of BITS Goa is a diverse group of students with interests ranging from electronics to machine learning to mechanical design. Over the years, we have evolved into a platform to learn and experiment with various aspects of science and engineering and to apply them in robotics. We are open to anyone with a general interest in engineering and who wants to explore robotics, so feel free to get in touch with us.</p> <p>This handbook is part of an effort from our side to provide an organised set of learning resources to make it easy for anyone to get started with the field of robotics. We have compiled a bunch of staple and commonly used resources in an orderly fashion giving a breadth-first overview of basic concepts essential in all the three significant verticals of robotics: Design, Electronics and Control and Automation.</p> <p>The field of robotics is very vast and rapidly moving forward, exploring new and unique things. Currently, the handbook has content related to introductory robotics, and our current effort is focused on including more relevant information and resources. We are open to and would love to have any contributions or suggestions from your side, helping us improve and add new material to the handbook. Feel free to open an issue or PRs to the repository :)</p> <p>We hope this handbook helps you in some or the other way!</p> <p>You can find out more about us at our website and read our blog articles.</p>"},{"location":"misc/","title":"Miscellaneous","text":""},{"location":"misc/#online-courses","title":"Online Courses","text":"<ul> <li>Underactuated robotics</li> <li>Programming for Robotics</li> <li>Introduction to Aerial Robotics</li> <li>SLAM Course</li> <li>Robotics Specialization - Coursera</li> <li>Modern Robotics Specialization - Coursera</li> <li>Compiled list of other courses/resources</li> </ul>"},{"location":"misc/#wesbites-with-resources","title":"Wesbites with resources","text":"<ul> <li>The Robotics Back-End</li> <li>RoboticsKnowledgeBase</li> </ul>"},{"location":"misc/#talk-series-seminars-podcasts","title":"Talk Series / Seminars / Podcasts","text":"<ul> <li>Artificial Intelligence Podcast by Lex Fridman</li> <li>Robotics Today</li> <li>MIT RoboSeminars</li> <li>Stanford - Robotics and Autonomous Systems Seminar</li> <li>CMU RI Robotics Seminars</li> </ul>"},{"location":"misc/#list-of-mailing-lists-and-google-groups","title":"List of Mailing lists and Google Groups","text":"<ul> <li> <p>Robotics Worldwide</p> </li> <li> <p>European Robotics</p> </li> <li> <p>AI Robotics</p> </li> <li> <p>Systems Neuroscience</p> </li> <li> <p>ML-news</p> </li> <li> <p>Connectionists</p> </li> <li> <p>UAI</p> </li> <li> <p>Reinforcement Learning</p> </li> <li> <p>Deep Learning</p> </li> <li> <p>Neuromorphic Engineering</p> </li> <li> <p>Computer Vision</p> </li> <li> <p>Artificial Life</p> </li> <li> <p>Genetic Programming</p> </li> </ul>"},{"location":"roadmap/","title":"Roadmap for Robotics","text":"<p>Robotics is a vast field which often overlaps with many other disciplines ranging from machine learning to physics. For a beginner this can be pretty intimidating, we know, we\u2019ve been there. To make it easier to get started, we have collected the following resources. You can also find more resources at our website.</p>"},{"location":"roadmap/#a-common-beginning","title":"A common beginning","text":"<p>As a beginner, the most important thing is to start learning a language since it opens up a lot of opportunities in terms of projects to work on and things to do.  Also keep in mind that once you know one language well, it\u2019s relatively easy to pick up another one quickly.</p> <p>In robotics, different languages have different uses:</p> <ol> <li>Automation: Machine Learning: python for basic stuff, C++ for more advanced stuff</li> <li>Embedded systems and electronics: C</li> <li>Modelling: python, MATLAB</li> </ol> <p>We would recommend starting with either python or C/C++. Knowing both is pretty much essential for advanced robotics. Here are some places where you can get started:</p>"},{"location":"roadmap/#python","title":"Python","text":"<ul> <li>Web tutorial</li> <li>Corey Schafer\u2019s video tutorials</li> </ul>"},{"location":"roadmap/#c","title":"C","text":"<ul> <li>FreeCodeCamp Video Tutorials</li> <li>Browser based tutorial</li> <li>Beej\u2019s Guide (follow if you already know programming)</li> </ul>"},{"location":"roadmap/#c_1","title":"C++","text":"<ul> <li>Welcome to C++ Playlist - YouTube</li> <li>Web tutorial</li> </ul>"},{"location":"roadmap/#matlab-simulink","title":"MATLAB &amp; Simulink","text":"<ul> <li>MATLAB Onramp and Simulink Onramp. These courses introduce you to the MATLAB and Simulink environments. Many other self paced courses can be found here.</li> <li>This interesting \u201cHow to\u201d playlist by MATLAB teaches some basics how to\u2019s with MATLAB &amp; Simulink, check out the videos which are required for solving any doubts.</li> <li>Versioning with Git this video will help with using Git &amp; Version control with your Simulink projects.</li> </ul>"},{"location":"roadmap/#development-environment","title":"Development Environment","text":"<p>Writing code isn\u2019t just as simple as typing into a text editor. Usually there are many other components involved such as a compiler, external libraries, path environments, a terminal, version control, documentation etc\u2026 Don\u2019t worry if you don\u2019t know what these things mean, together they are generally known as your development environment. To begin with, make sure you are comfortable with the following</p> <ul> <li>Linux Operating System: Linux is an open source operating system - this means that anyone can view and propose changes to its source code. It comes in many variants, Ubuntu being the recommended choice for beginners. It\u2019s essential to have access to linux (either through dual booting, virtual machine or WSL - more on these here) due to its tight integration with many of the tools used to program robots (and development in general).</li> <li>Linux Terminal: While most of us are familiar with the point and click based interface of windows, computers first started off as terminals - text based prompts that you had to type into. The terminal is still used for pretty much everything in software development and is an essential skill. YouTube Tutorial</li> <li>Git: When working on complex code, or as part of a team, keeping track of changes to the code becomes very important. Git provides a way to do this and much more. Platforms such as GitHub and GitLab have become the bedrock of the open source community in recent years. YouTube Tutorial</li> </ul>"},{"location":"roadmap/#electronics","title":"Electronics","text":"<p>The Electronics part of Robotics can be divided into 3 parts : Microcontroller, Sensors and Actuators. Sensors and Actuators (through drivers) are interfaced with the microcontroller to form the electronics system of the robot. Basic electronics components like wires, resistors, capacitors are used in interfacing and this whole assembly is mounted on a breadboard, prototyping board or a printed circuit board (Based on the stage of the project).</p> <p>To start off with learning about microcontrollers (structure, layout, how to program) one is advised to start with learning Arduino. Arduino is a low cost, open source and easy to learn microcontroller. The syntax used to program Arduino is similar to that of C/C++ and a software called Arduino IDE is used to program it. Arduino has its own set of official tutorials. One can also find many tutorials on YouTube channels like Jeremy Blum, Paul McWhorter, etc. There is also a basic tutorial and more info regarding Arduino IDE, from us over here. There is an online simulator which is capable of simulating Arduino projects, called TinkedCad, in case one is not willing to buy an Arduino board.</p> <p>After learning Arduino and understanding the basic concepts regarding working of a microcontroller one can dive deep and try out other microcontrollers like STM32 (BluePill), etc.</p> <p>Sensors are electronic components used by the robot to get information about the environment. Some few examples of sensors are wheel encoders, temperature sensors, depth cameras (Kinect), LiDARs, Ultrasound sensors, etc. On the other hand actuators are components using which the robot brings about changes in the environment. Ex. Motors (DC, Stepper, Servo, BLDC), Linear Actuators (Solenoid or a linear servo), etc. Actuators are interfaced with the microcontroller using drivers because of the different power budgets of the microcontroller and the actuators.</p> <p>After interfacing one might want to assemble it on a prototyping board or even a PCB (for long term use). A software called EAGLE is used to design a PCB. One can download and install it free of cost from the official website of AutoDesk. Tutorials on Jeremy Blum\u2019s and Terminal Two\u2019s YouTube Channel are a great place to start PCB designing using EAGLE.</p>"},{"location":"roadmap/#automation","title":"Automation","text":""},{"location":"roadmap/#robot-operating-system-ros","title":"Robot Operating System (ROS)","text":"<p>Think about how you might go about automating a human like robot that helps out at home. Would you just write one big program to control all its behaviour (navigation, motion, obstacle detection, battery monitoring, speech processing etc..)? The much smarter thing to do would be to have smaller independent programs for each of these which can communicate with each other (i.e one program for moving around, one for talking, one for picking things up etc..).  The problem that arises now is how would these individual programs communicate. The Robot Operating System provides a solution for this. It is not an actual OS, rather a framework which makes communication and coordination easier. Check out this and this video, and this text for more.</p> <p>To setup your ROS environment check out this.</p> <p>The official ROS tutorials are very good for introduction. The concepts are given in a concise manner, and a lot of example code (Python as well as C++) is given for understanding. Also read about various ROS parameters here.</p> <p>In case of specific questions, try googling them. Many questions might have been asked before by someone else and an answer might be available on ROS Answers.</p> <p>A Recommended course: Hello (Real) World with ROS - Robot Operating System - TU Delft OCW</p> <p>Also refer Morgan Quigley\u2019s Programming Robots with ROS</p>"},{"location":"roadmap/#path-planning","title":"Path Planning","text":"<p>Path planning is the process of \u201cfinding\u201d a path or a trajectory for a robot by avoiding obstacles or following set dynamic or kinematic constraints of a robot. Quite literally, it\u2019s something we as humans do quite instinctively, but robots find it difficult and we try to make them \u201cintelligent\u201d by using some algorithms which can be called as path planning algorithms. Path planning plays an integral part in robot automation because most of the robots have to plan a path. Even in the case of robotic arms, moving the end effector from a given spatial coordinate to another given spatial coordinate requires \u201cplanning of a trajectory\u201d the arm must follow. However, the constraints and dimensions for planning the path or trajectory are different from that used to plan in a ground robot. Read more over here.</p> <p>Most of the old planning algorithms have many implementations. Check out this book for an in-depth introduction. The best way to learn about any planning algorithm is to look for the research paper and go through it. Read about Graph based algorithms like A Star and Dijkstra here. Some information about a Sampling based algorithm - RRT can be found here.</p> <p>However, to find some implementations of the algorithms, you can refer to the Open Motion Planning Library for industry-level implementations of the algorithms. (OMPL is written in C/C++, beware!!). For a better understanding and visualisation of how various algorithms work, take a look at this repository. It\u2019s written in python!</p>"},{"location":"roadmap/#simultaneous-localization-and-mapping-slam","title":"Simultaneous Localization and Mapping (SLAM)","text":"<p>As the name suggests, what SLAM achieves is simultaneously map and localise in an environment. Historically, mapping and localization were done individually. Doing both of them simultaneously poses some difficulties. Check out the playlist by Cyrill Stachniss on SLAM for an in-depth course. Linear algebra and Probability and Statistics are quite important for a better understanding.</p>"},{"location":"roadmap/#robot-perception","title":"Robot Perception","text":"<p>Robot Perception is something that is really underappreciated by beginners as the difficulties behind it are not properly understood. It\u2019s quite hard to comprehend how hard can seeing, analysing and extracting useful data from a 3D world can be for a robot, as we as humans are quite comfortable in picking and placing objects that are in front of us with utmost precision. It\u2019s easy for us to avoid tripping over a branch while walking(of course if we see it). But the same is very complex for robots.  Robot Perception specifically deals with this aspect of making intelligent robots.</p> <p>To understand how a robot perceives the environment, you need to know about the depth map, how we create it and what are its uses (this is a resource using which you can make a depth map yourselves. Generally, depth maps are made by using two cameras, each giving a different perspective of the same scene, thus creating a depth image, just like our eyes). Using depth maps is one of the classical methods of analysing a 3D environment.</p> <p>Sensors play an important role in any robotic task. High-quality Cameras, LiDARs etc are used. To get started with perception by using images, OpenCV is a good starting point. For perception using Point Clouds, Point Cloud Library is a good starting point(PCL can only be used using C++).</p> <p>There are many advancements that are taking place. With the advent of Neural Networks, Convolution Neural Networks(CNN\u2019s) are used to extract and analyse important information from depth maps thus enabling image and point cloud segmentation, classification tasks etc.</p>"},{"location":"roadmap/#machine-learning-ai","title":"Machine Learning / AI","text":"<p>Much of the computer based tools we use follow the same principle - they are a collection of  straightforward instructions for the computer to follow so that it can solve a task. Machine Learning on the other hand, is about how the computer can learn to solve a task from examples, much like we humans learn.</p> <ul> <li> <p>Courses</p> <ul> <li>Andrew Ng\u2019s classic machine learning course is generally a good place to start.Note that the exercises are in Octave/MATLAB but it\u2019s recommended to try them out in python. This repository has a translated version of the exercises.</li> <li>Deep Learning by deeplearning.ai is a more advanced course by Andrew NG focusing on Deep Learning.</li> <li>After completing one of the above, to explore more advanced subfields within machine learning, Stanford has a good set of courses<ul> <li>Computer Vision (recommended to do this before the other two)</li> <li>Natural Language Processing</li> <li>Reinforcement Learning (also check out this book)</li> </ul> </li> </ul> </li> <li> <p>Software Tools</p> <ul> <li>Numpy: Mathematics and Linear Algebra library for python. Essential to know. YouTube Tutorial | Documentation</li> <li>Matplotlib: Plotting library for python. Essential to know. YouTube Tutorial | Documentation</li> <li>SciKitLearn: Machine Learning toolkit in python. YouTube Tutorial | Documentation</li> <li>OpenCV: Computer vision toolkit YouTube Tutorial | Documentation</li> <li>Pytorch: Deep Learning framework YouTube Tutorial | Documentation</li> <li>Tensorflow: Deep Learning framework YouTube Tutorial | Documentation</li> </ul> </li> </ul>"},{"location":"roadmap/#control-systems","title":"Control Systems","text":"<p>Control systems help to control the movements and functions of the robot. We need the controllers because the dynamics vary with the time. When the robot moves up in a slope and then down in the slope, or first travels on smooth concrete, then on a carpeted floor. So physical modelling of the \u201cSystem\u201d becomes crucial for designing a good controller.</p> <p>We give a reference state to a controller. The controller also has sensor feedback, using the reference state and sensor feedback controller generates a control signal needed to reach the reference state. This control signal is fed to the \u201cSystem\u201d. The system dynamics determine how the system behaves to this control input. If the controller is good, hopefully, the \u201cSystem\u201d will reach our desired reference state. For more check this.</p> <ul> <li>To get started with control systems and theory - Control of Mobile Robots course by Magnus Egerstedt (Georgia Tech), also on Coursera by the same name.</li> <li>Understanding PID Control - Playlist by MATLAB explains PID control in detail. Also read about the controller over here.</li> <li>Read about more advanced controllers like Linear-Quadratic Regulator (LQR) and Model Predictive Control (MPC) here.</li> <li>This playlist teaches some more basic concepts of Control Theory and how to practically apply them.</li> <li>This playlist teaches State space equations, pole placement and concepts like controllability. These become essential when dealing with the math behind Control Theory.</li> </ul>"},{"location":"roadmap/#mechanical-design","title":"Mechanical Design","text":""},{"location":"roadmap/#cad","title":"CAD","text":"<p>Fusion360 is a good starting point to get yourself familiar with 3D modelling to model anything you can think of! This is the link from where it can be downloaded. Make sure you have an Autodesk account linked with your institute id for free access.</p> <p>To get started with it check out official tutorials on Autodesk website.</p> <p>SOLIDWORKS by Dassault Systems is a major CAD platform that is used for 3D design and basic simulations. It has slightly more functionalities than F360 and is very good for the design of manufactured goods and design engineering. You can easily find SW tutorials on Youtube, however, this Lynda tutorial series on SW is very nice- Lynda Tutorials SolidWorks. [Use BITS mail]</p> <p>For more information on how to get Solidworks, get in touch with an ERC member.</p>"},{"location":"automation/intro/","title":"Introduction","text":"<p>Robots would be pretty useless without having the ability to do stuff on their own. Today, with ever more powerful machine learning techniques, robots are on their way to becoming truly autonomous.  Different aspects of Automation include Planning, Controls and State estimation.</p> <p>From the moment we wake up in the morning until our head hits the pillow at night, we must plan our actions. A large problem in the development of autonomous robots is devising a way to give them the capabilities to make their own plans in a variety of situations.  Motion planning refers to the computational process of moving from one place to another in the presence of obstacles.</p> <p>The Robot control system directs the motion and sensory processing of a robot .We need the controllers for the robot because the dynamics (system plant) vary with the time. Such as when the robot moves up in a slope and then down in the slope, or first travels on smooth concrete, then on a carpeted floor.</p> <p>A key aspect of robotics today is estimating the state, such as position and orientation, of a robot as it moves through the world. Most robots and autonomous vehicles depend on noisy data from sensors such as cameras or laser rangefinders or a combination of these to localise themselves in a three-dimensional world.</p>"},{"location":"automation/ControlTheory/Control_Theory/","title":"Control Theory","text":"<p>A robot can exhibit a number of different behaviors, depending on the task and its environment. It can act as a source of programmed motions for tasks such as moving an object from one place to another or tracing a trajectory. It can act as a source of forces, as when applying a polishing wheel to a workpiece. In tasks such as writing on a chalkboard, it must control forces in some directions (the force must press the chalk against the board) and motions in others (the motion must be in the plane of the board). When the purpose of the robot is to act as a haptic display, rendering a virtual environment, we may want it to act like a spring, damper, or mass, yielding in response to forces applied to it.</p> <p>In each of these cases, it is the job of the robot controller to convert the task specification to forces and torques at the actuators. Control strategies that achieve the behaviors described above are known as motion control, force control, hybrid motion-force control, or impedance control.</p> <p></p> <p>A typical control block diagram is shown above The sensors are typically: potentiometers, encoders, or resolvers for joint position and angle sensing; tachometers for joint velocity sensing; joint force-torque sensors; and/or multi-axis force-torque sensors.</p>"},{"location":"automation/ControlTheory/Control_Theory/#types-of-control-systems","title":"Types of control systems","text":""},{"location":"automation/ControlTheory/Control_Theory/#open-loop-control-system","title":"Open Loop control system","text":"<p>A control system in which the control action is totally independent of output of the system then it is called open loop control system. A manual control system is also an open loop control system. The figure below shows a control system block diagram of an open loop control system in which process output is totally independent of the controller action.</p> <p></p> <p>Practical examples of Open loop control system:</p> <ol> <li>Electric Hand Drier \u2013 Hot air (output) comes out as long as you keep your hand under the machine, irrespective of how much your hand is dried.</li> <li>Automatic Washing Machine \u2013 This machine runs according to the pre-set time irrespective of washing is completed or not.</li> <li>Bread Toaster \u2013 This machine runs as per adjusted time irrespective of toasting is completed or not.</li> </ol>"},{"location":"automation/ControlTheory/Control_Theory/#closed-loop-control-system","title":"Closed Loop control system","text":"<p>Control system in which the output has an effect on the input quantity in such a manner that the input quantity will adjust itself based on the output generated is called closed loop control system. Open loop control system can be converted in to closed loop control system by providing a feedback. Figure below shows the block diagram of closed loop control system in which feedback is taken from output and fed in to input.</p> <p></p> <p>Practical example of Closed loop control system:</p> <ol> <li>Missile Launched and Auto Tracked by Radar \u2013 The direction of missile is controlled by comparing the target and position of the missile.</li> <li>An Air Conditioner \u2013 An air conditioner functions depending upon the temperature of the room.</li> <li>Cooling System in Car \u2013 It operates depending upon the temperature which it controls.</li> </ol>"},{"location":"automation/ControlTheory/Control_Theory/#core-topics-in-control-theory","title":"Core topics in Control Theory","text":"<p>Before we design any controller, we have to consider the key factors that will drive the robot and how are we supposed to build the controller that will drive us to the best results which are also known as control objectives. These factors are listed below:</p> <p>1.Stability : By this, we mean to measure the level of stability in the signal which will drive the object and also keep a check on the fluctuation of the signal. For eg. if we are making a cruise controller for a car, then the controller should give a stable signal after the car has reached the cruising speed and the speed should remain constant (no fluctuations).</p> <p>2.Tracking : It is necessary to give controls after analyzing the response given due to the input signal. For instance, in a cruise controller, after setting up cruising speed, it is necessary for the controller to keep a regular check on the speed by which it can decide whether to accelerate or retard.</p> <p>3.Robustness : Robust control systems often incorporate advanced topologies which include multiple feedback loops and feed-forward paths. The control laws may be represented by high order transfer functions required to simultaneously accomplish desired disturbance rejection performance with robust closed loop operation. For example, the controller should not be hard coded to function only for a certain velocity ,say 50 miles/hour if designing a cruise control.</p> <p>4.Disturbance : It refers to the noise (not useful signal) that the controller might signal while sending or any sort of attenuation that can happen. It actually depends on the quality of instruments used in making a controller and also due to some external factors.</p> <p>5.Optimality : It is a set of differential equations that describe the paths of the control variables that minimize the cost function.</p>"},{"location":"automation/ControlTheory/Control_Theory/#laplace-transform","title":"Laplace transform","text":"<p>The Laplace transform plays a important role in control theory. It appears in the description of linear time invariant systems, where it changes convolution operators into multiplication operators and allows to define the transfer function of a system. The properties of systems can be then translated into properties of the transfer function. It allows the use of graphical methods to predict system performance without solving the differential equations of the system. These include response, steady state behavior, and transient behavior.</p>"},{"location":"automation/ControlTheory/Control_Theory/#laplace-vs-fourier-transform","title":"Laplace Vs Fourier transform","text":"<p>Laplace transform: \\(F(s)=\\int_{0}^{\\infty}f(t)e^{-st}dt  \\qquad f^{'}(t)\\Rightarrow sF(s)\\) Fourier transform: \\(F(\\omega) = \\int_{-\\infty}^{\\infty}f(t)e^{-j\\omega t}dt\\) Laplace transforms often depend on the initial value of the function whereas Fourier transforms are independent of the initial value. The transforms are only the same if the function is the same both sides of the y-axis (so the unit step function is different). </p> <p>To understand Laplace transform in detail read this article</p>"},{"location":"automation/ControlTheory/Control_Theory/#closed-loop-transfer-function","title":"Closed Loop Transfer Function","text":"<p>A closed-loop transfer function in control theory is a mathematical expression describing the net result of the effects of a closed feedback loop on the input signal to the circuits enclosed by the loop.</p> <p></p> <p>Where: block G represents the open-loop gains of the controller or system and is the forward path, and block H represents the gain of the sensor, transducer or measurement system in the feedback path.</p> <p>To find the transfer function of the closed-loop system above, we must first calculate the output signal \u03b8o in terms of the input signal \u03b8i. To do so, we can easily write the equations of the given block-diagram as follows.</p> <p>The output from the system is equal to:  Output = G x Error</p> <p>Note that the error signal, \u03b8e is also the input to the feed-forward block: G</p> <p>The output from the summing point is equal to:  Error = Input - H x Output</p> <p>If H = 1 (unity feedback) then:</p> <p>The output from the summing point will be:  Error (\u03b8e) = Input - Output</p> <p>Eliminating the error term, then:</p> <p>The output is equal to:  Output = G x (Input - H x Output)</p> <p>Therefore:  G x Input = Output + G x H x Output</p> <p>Rearranging the above gives us the closed-loop transfer function of:</p> <p></p>"},{"location":"automation/ControlTheory/Control_Theory/#controllability","title":"Controllability","text":"<p> <p> </p>"},{"location":"automation/ControlTheory/Control_Theory/#types-of-feedback-control","title":"Types of Feedback Control","text":""},{"location":"automation/ControlTheory/Control_Theory/#positive-feedback","title":"Positive Feedback","text":"<p>In a \u201cpositive feedback control system\u201d, the set point and output values are added together by the controller as the feedback is \u201cin-phase\u201d with the input. The effect of positive (or regenerative) feedback is to \u201cincrease\u201d the systems gain, i.e, the overall gain with positive feedback applied will be greater than the gain without feedback]</p>"},{"location":"automation/ControlTheory/Control_Theory/#negative-feedback","title":"Negative Feedback","text":"<p>In a \u201cnegative feedback control system\u201d, the set point and output values are subtracted from each other as the feedback is \u201cout-of-phase\u201d with the original input. The effect of negative (or degenerative) feedback is to \u201creduce\u201d the gain. As a rule negative feedback systems are more stable than positive feedback systems. Negative feedback also makes systems more immune to random variations in component values and inputs.</p> <p></p> <p>To know more about different types of control systems you can read this article.</p>"},{"location":"automation/ControlTheory/LQR/","title":"Linear-Quadratic Regulator(LQR) Controller","text":"<p>The theory of optimal control is concerned with operating a dynamic system at minimum cost. The case where the system dynamics are described by a set of linear differential equations and the cost is described by a quadratic function is called the LQ problem. One of the main results in the theory is that the solution is provided by the linear\u2013quadratic regulator (LQR).</p> <p>The settings of a (regulating) controller governing either a machine or process (like an airplane or chemical reactor) are found by using a mathematical algorithm that minimizes a cost function with weighting factors needed to be supplied. A cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \u201ccost\u201d associated with the event. The cost function is often defined as a sum of the deviations of key measurements, like altitude or process temperature, from their desired values. The algorithm thus finds those controller settings that minimize undesired deviations. The magnitude of the control action itself may also be included in the cost function.</p>"},{"location":"automation/ControlTheory/LQR/#finite-horizon-lqr","title":"Finite horizon LQR","text":"<p>For a continuous-time linear system, defined on \\(t \\epsilon [t_0,t_1]\\) , described by: \\(\\dot{x} = Ax + Bu\\)</p> <p>with a quadratic cost function defined as: \\(J = x^T (t_1)F(t_1)x(t_1) + \\int_{t_0}^{t_1} (x^TQx + u^TRu + 2x^TNu) \\,dt\\) the feedback control law that minimizes the value of the cost is: \\(u = -Kx\\) where K is given by: \\(K = R^{-1}(B^TP(t) + N^t)\\) and P is found by solving the continuous time Riccati differential equation: \\(A^TP(t) + P(t)A - (P(t)B+N)R^{-1}(B^TP(t) + N^T) + Q = - \\dot{P}(t)\\) with the boundary condition: \\(P(t_1)=F(t_1)\\)</p> <p>To learn more in detail about LQR controller watch this video by Steve Brunton</p>"},{"location":"automation/ControlTheory/LQR/#linear-quadratic-gaussian-lqg-control-theory","title":"Linear Quadratic Gaussian (LQG) control theory","text":"<p>Here, Given a linear model of the plant in a statespace description, and assuming that the disturbance and measurement noise are Gaussian stochastic processes with known power spectral densities, the designer translates the design specifications into a quadratic performance criterion consisting of some state variables and control signal inputs. The object of design then is to minimize the performance criterion by using appropriate state or measurement feedback controllers while guaranteeing the closed-loop stability. When LQG controller problem is solved in a deterministic setting, known as an  H2 optimal control problem, in which the H2 norm of a certain transfer function from an exogenous disturbance to a pertinent controlled output of a given plant is minimized by appropriate use of an internally stabilizing controller.</p> <p>To learn about robust controllers and LQG control problem in detail watch this video</p> <p>H\u221e (i.e. \u201cH-infinity\u201d) methods are used in control theory to synthesize controllers to achieve stabilization with guaranteed performance. To use H\u221e methods, a control designer expresses the control problem as a mathematical optimization problem and then finds the controller that solves this optimization. H\u221e techniques have the advantage over classical control techniques in that H\u221e techniques are readily applicable to problems involving multivariate systems with cross-coupling between channels.</p> <p>Read this material from MIT Open Courseware  to know about H\u221e methods in more detail.</p>"},{"location":"automation/ControlTheory/MPC/","title":"Model Based Controllers","text":"<p>Model-based control uses information about the dynamics of the system\u2019s structure and its behavior in time to obtain a better control result regarding stability and performance of the controlled system. Take the following simple example:</p> <p>Let \\(\\frac{d^2x}{dt^2}= f(x)+u\\)</p> <p>be the system to be controlled, where x - state vector, f(x) - nonlinear vector function, u - control vector. Suppose we have some estimation est(x) than we use a control law like  \\(u = -est(x)+u_{st}\\) where ust be some maybe linear PID control law \\(u_{st} = K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) So we get \\(\\frac{d^2x}{dt^2} = \\Delta f + K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) where  \\(\\Delta f =f(x) - est(x)\\) If the model uncertainties are small enough we get a linear system with a disturbance Delta f which can be stabilized using appropriate control gains Kp, Kd, KI. Above given is just an example of model based controller in real life model based controller are way more complex than this.</p> <p>Model Predictive Control(MPC) is the most widely known model based controller. Model Predictive Controllers rely on the dynamic models of the process, most often linear empirical models obtained by system identification.</p> <p>Model predictive control offers several important advantages:</p> <p>(1) the process model captures the dynamic and static interactions between input, output, and disturbance variables,</p> <p>(2) constraints on inputs and outputs are considered in a systematic manner,</p> <p>(3) the control calculations can be coordinated with the calculation of optimum set points, and</p> <p>(4) accurate model predictions can provide early warnings of potential problems.</p> <p>The mathematics and concepts involved in MPC are a bit complex and require a decent understanding of mathematics of control theory. </p> <p>To study more about MPC controller read this material by NTNU</p> <p>You can also check this video by Steve Brunton to get a more detailed idea</p> <p>Some of the other resources you should check to understand control theory and various controllers in more detail are:</p> <ol> <li>Control Bootcamp playlist by Steve Brunton</li> <li>Control Systems Lectures by Brian Douglas</li> <li>Control of Mobile Robots course by Georgia Tech University on Coursera</li> <li>Modern Robotics - Mechanical, Planning and Control by Kevin.M.Lynch and Frank.C.Park</li> <li>MIT Courseware Control Theory Notes</li> </ol>"},{"location":"automation/ControlTheory/PID_Controller/","title":"PID Controller","text":""},{"location":"automation/ControlTheory/PID_Controller/#linear-control-techniques","title":"Linear Control Techniques","text":"<p>Linear Control technique is the most widely used technique for designing control systems in robotics because of its simple implementation when your system is operating in vicinity of a particular point. Some of the common linear control system design techniques, includes the well-known PID control, H2 and H\\(\\infty\\) optimal control, linear quadratic regulator (LQR) with loop transfer recovery design (LTR) , and some newly developed design techniques, such as the robust and perfect tracking (RPT) method.</p>"},{"location":"automation/ControlTheory/PID_Controller/#pid-controller","title":"PID Controller","text":"<p>PID control is the most popular technique used in industries because it is relatively easy and simple to design and implement. Most importantly, it works in most practical situations, although its performance is somewhat limited owing to its restricted structure.</p> <p></p> <p>Hence, a PID control law has the following general form for the input command: \\(u(t) = K~p~e(t) + K~i~\\int e(t) + K~d~\\frac{de(t)}{dt}\\) where \\(e = q - q~d~\\) is the error signal, and \\(K~p~, K~i~\\) and \\(K~d~\\) are positive constant gains associated with proportional, integral, and derivative controllers.</p> <p>Consider the control system , in which G(s) is the plant to be controlled and K(s) is the PID controller, it can be characterized by the following transfer function: \\(K(s) = K~p~(1+\\frac{1}{Tis}+Tds)\\) The control system design is then to determine the parameters Kp , Ti and Td such that the resulting dosed-loop system yields a certain desired performance, i.e. it meets certain prescribed design specifications.</p>"},{"location":"automation/ControlTheory/PID_Controller/#proportional-factor","title":"Proportional factor","text":"<p>The proportional factor is easiest to understand: The output of the proportional factor is the product of gain and measured error \u03b5. Hence, larger proportional gain or error makes for greater output from the proportional factor. Setting the proportional gain too high causes a controller to repeatedly overshoot the setpoint, leading to oscillation.</p> <p>The downside to a proportional-only loop is that when error becomes too small, loop output becomes negligible. Therefore, even when the proportional loop reaches steady state, there is still error. The larger the proportional gain, the smaller the steady state error \u2014 but the larger the proportional gain, the more likely the loop is to become unstable. This dilemma leads to inevitable steady-state error called offset.</p> <p></p>"},{"location":"automation/ControlTheory/PID_Controller/#integral-factor","title":"Integral Factor","text":"<p>The main function of an integral control is to eliminate the steady state error and make the system follow the set point at steady state conditions. The integral controller leads to an increasing control command for a positive error, and a decreasing control command for a negative error. The downside to the integral factor is that it strongly contributes to controller output overshoot past the target setpoint. The shorter the integral time, the more aggressively the integral works.</p> <p></p>"},{"location":"automation/ControlTheory/PID_Controller/#derivative-factor","title":"Derivative Factor","text":"<p>The purpose of derivative control is to improve the closed-loop stability of a system. A derivative controller has a predicting action by extrapolating the error using a tangent to the error curve. The derivative factor is the least understood and used of the three factors. In fact, a majority of PID loops in the real world are really just PI loops. A properly used derivative allows for more aggressive proportional and integral factors.</p> <p></p>"},{"location":"automation/ControlTheory/PID_Controller/#pid-tuning-method","title":"PID Tuning Method","text":"<p>The determination of corresponding PID parameter values for getting the optimum performance from the process is called tuning. This is obviously a crucial part in case of all closed loop control systems. There are number of tuning methods have been introduced to obtain fast and acceptable performance.</p>"},{"location":"automation/ControlTheory/PID_Controller/#trial-and-error-method","title":"Trial and Error Method","text":"<p>This is the simple method of tuning a PID controller. Once we get the clear understanding of PID parameters, the trial and error method become relatively easy.</p> <ul> <li>Set integral and derivative terms to zero first and then increase the proportional gain until the output of the control loop oscillates at a constant rate. This increase of proportional gain should be in such that response the system becomes faster provided it should not make system unstable.</li> <li>Once the P-response is fast enough, set the integral term, so that the oscillations will be gradually reduced. Change this I-value until the steady state error is reduced, but it may increase overshoot.</li> <li>Once P and I parameters have been set to a desired values with minimal steady state error, increase the derivative gain until the system reacts quickly to its set point. Increasing derivative term decreases the overshoot of the controller response.</li> </ul>"},{"location":"automation/ControlTheory/PID_Controller/#zeigler-nichols-method","title":"Zeigler-Nichols Method","text":"<p>It is another popular method for tuning PID controllers. Ziegler and Nichols presented two classical methods for determining values of proportional gain, integral time and derivative time based on transient response characteristics of a given plant or system.</p>"},{"location":"automation/ControlTheory/PID_Controller/#first-method","title":"First Method","text":"<ul> <li>Obtain a unit step response of the plant experimentally and it may look\u2018s\u2019 shaped curve as shown in figure below. This method applies, if obtained response exhibit s-shaped curve for unit step input otherwise it cannot be applied. This curve can also be obtained by dynamic simulation of the plant.</li> </ul> <ul> <li>Obtain two constants, delay time L and time constant T by drawing a tangent line at the inflection point of the s-shaped curve.</li> <li>Set the parameters of Kp, Ti , and Td values from the table given below for three types of controllers."},{"location":"automation/ControlTheory/PID_Controller/#second-method","title":"Second Method","text":"<ul> <li>It is very similar to the trial and error method where integral and derivative terms are set to the zero, i.e., making Ti infinity and Td zero.</li> <li>Increase the proportional gain such that the output exhibits sustained oscillations. If the system does not produce sustained oscillations then this method cannot be applied. The gain at which sustained oscillations produced is called as critical gain.</li> </ul> <ul> <li>Once the sustain oscillations are produced, set the values of Ti and Td as per the given table for P, PI and PID controllers based on critical gain and critical period.</li> </ul> <p> Recently many intelligent methods have also been developed for tuning PID controllers one of such method is using genetic algorithms. To learn more about this method watch this 2 part video by Steve Brunton.</p>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/","title":"A-Star Algorithm","text":"<p>A-star is a graph-based, path search algorithm. It is used in many fields of computer science as a search algorithm. It is often used due to its completeness, optimality, and optimal efficiency.</p>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#salient-features-of-the-algorithm","title":"Salient Features of the Algorithm","text":"<ol> <li>Resolution complete and Resolution optimal : The algorithm finds the optimal solution to the given problem at a chosen discretization, if one exits.</li> <li>A-Star uses a hueristic to estimate the total cost of a solution constrained to pass through a state. Thus, it searches in order of decreasing solution quality and is optimally efficient.</li> <li>Any other optimal algorithm using the same hueristic will expand at least as many vertices as A-Star.</li> </ol>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#idea-of-hueristics-functions","title":"Idea of Hueristics Functions","text":"<ul> <li>Hueristic functions are used to map every node in the graph to a non-negative value.</li> <li> </li> <li> </li> </ul> <p>Where \\(x_n\\), \\(y_n\\) and \\(x_g\\), \\(y_g\\) are the \\(x\\), \\(y\\) coordinates of a the node and the goal respectively.</p>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#criteria-for-hueristics-functions","title":"Criteria for Hueristics Functions","text":"<ul> <li>Should be a monotonic function</li> <li>Should satisfy \\(H(goal) = 0\\)</li> <li>For any two adjacent nodes \\(x\\) and \\(y\\):<ul> <li>\\(H(x, y) \\leq H(y) + d(x, y)\\) </li> <li>\\(d(x, y) = EdgeCost(x, y)\\)</li> </ul> </li> <li>These properties ensure that for all nodes \\(n\\):<ul> <li>\\(H(n) \\leq length of Shortest Path(n, GOAL)\\)</li> </ul> </li> </ul>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#for-path-planning-on-a-grid","title":"For path Planning on a grid:","text":"<ul> <li>Euclidean Distance: \\(H(x_n, y_n) = \\sqrt{(x_n-x_g)^2 + (y_n-y_g)^2}\\)</li> <li>Manhattan Distance: \\(H(x_n, y_n) = \\lvert(x_n - x_g) + (y_n - y_g)\\rvert\\)</li> </ul>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#psuedo-code-for-the-algorithm","title":"Psuedo Code for the Algorithm","text":"<pre><code>def Astar(start, goal, graph):\n    # Set the g, f values for all nodes in the graph\n    for node in graph:\n        node.f = Infinity\n        node.g = Infinity\n\n    # Create an empty list to store visited nodes\n    nodes = []\n\n    # Add Start to nodes list\n    nodes.add(start)\n\n    # Loop to traverse the graph\n    while nodes is not EMPTY:\n        # Obtain bode with the least f-value\n        CURRENT = argmin(node, criteria=node.f)\n\n        # Check if current node is the goal Node\n        # which means the graph has been completely traversed\n        if CURRENT == goal:\n            report \"SUCCESS\"\n            break\n        # Update parameters for adjacent nodes\n        for adjacent_node in CURRENT.adjacent_nodes:\n            if adjacent_node.g &gt; CURRENT.g + cost of edge from n to current:\n                adjacent_node.g = CURRENT.g + cost of edge from n to current\n                adjacent_node.f = adjacent_node.g + H(node)\n                adjacent_node.parent = CURRENT\n\n                # Add the adjacent node to nodes list if not there already\n                if adjacent_node not in nodes:\n                    nodes.add(adjacent_node)\n</code></pre> <p>Notations in the Psuedo Code explained:</p> <pre><code>g-value = distance between a node and the start node\nH-function = Hueristic funciton\nf-value = g-value + Hueristic value of the node\n</code></pre>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Astar/#references","title":"References","text":"<ol> <li>Original paper on A-Star path planning algorithm.</li> <li>Psuedo Code can be found here</li> <li>Video explainig A-star can be found here</li> </ol>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Dijkstra/","title":"Dijkstra\u2019s Algorithm","text":"<p>Dijkstra\u2019s Algorithm is an algorithm for finding the shortest path between one source node and all the other nodes in a graph, thereby producing a <code>shortest-path-tree</code>.</p>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Dijkstra/#psuedo-code","title":"Psuedo Code","text":"<pre><code># Set the distances if all nodes in the graph to infinty\nfor node in graph:\n    node.distance = INFINITY\n\n# Create an empty list\nnodes = []\n\n# Set the start distance to ZERO\nSTART.distance = 0\n\n# Add start to the list\nnodes.add(START)\n\n# Loop to update distances\nwhile nodes is not empty:\n    CURRENT = argmin(node, criteria=node.distance)\n\n    if CURRENT == GOAL:\n        report \"Success\"\n        break\n\n    for adjacent_node in CURRENT.adjacent_nodes:\n        if adjacent_node.distance &gt; CURRENT.distance + cost of edge from CURRENT to adjacent_node:\n            adjacent_node.distance = CURRENT.distance + cost of edge from CURRENT to adjacent_node\n            adjacent_node.parent = CURRENT\n\n            # Add adjacent_node to the list, if it is not already present\n            if adjacent_node not in nodes:\n                nodes.add(adjacent_node)\n</code></pre>"},{"location":"automation/PathPlanners/Graph_Based_Algorithms/Dijkstra/#references","title":"References:","text":"<ol> <li>Psuedo Code for Dijkstra\u2019s Algorithm can be found here</li> <li>A video explaining Dijkstra\u2019s Algorithm can be found here</li> </ol>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/","title":"Path Planning in Robotics","text":""},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#what-is-a-path","title":"What is a path?","text":"<p>Path, as the name suggests is a set of waypoints which a Robot is expected to travel. There can be many criterions for deciding a path that the Robot should follow. Various optimisations, checks are made before deciding an optimial path.</p>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#why-planning-is-important-for-autonomous-robots","title":"Why Planning is important for Autonomous Robots?","text":"<p>Path planning is one of the most important primitives for autonomous mobile robots. The ability to be able to travel on its own by finding a collision free, optimal path is an important aspect of making robots autonomous</p>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#path-planning-for-autonomous-robots","title":"Path planning for Autonomous Robots","text":"<p>Path planning, as illustrated above is an important aspect of autonomous robots. There are various methods how a path is planned. There are various algorithms on path planning. Some of the common features of path planners are: 1. Given a start and a goal position(or pose), give out a set of states(positions or velocities) that the robot should take to reach the goal from start. 2. The path generated should be collision free with the obstacles in the environment. 3. Generally the path generated should optimise some hueristic(or parameter). 4. The path generated should be traversable by a robot given its dynamics.</p>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#path-planning-algorithms","title":"Path Planning algorithms","text":"<p>The problem to find an optimal path has been studied since many decades. There are many algorithms that are <code>graph-based</code>, <code>sampling-based</code>. Each branch follows a particular approach to solve the path planning problem.</p>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#1-graph-based-algorithms","title":"1. Graph based algorithms:","text":"<p>Graph based algorithms overlay a topological graph on a robots configurational space and perform search for an optimal path. Some of the notable graph-based algorithms are:</p> <ul> <li>Dijkstra\u2019s Algorithm</li> <li>A-Star (A*)</li> <li>D-Star (D*)</li> </ul>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#2-sampling-based-algorithms","title":"2. Sampling based algorithms:","text":"<p>Sampling based algorithms represent the configuration space with a roadmap or build a tree, generated by randomly sampling states in the configuration space. Some of the notable sampling-based algorithms are:</p> <ul> <li>Rapidly exploring Random Tree (RRT)</li> <li>RRT Star (RRT*)</li> <li>Informed RRT Star</li> <li>Batch Informed Trees Star (BIT*)</li> </ul>"},{"location":"automation/PathPlanners/Introduction_to_Path_Planning_in_Robotics/intro/#additional-references","title":"Additional References","text":"<ol> <li>For a better understanding of the path planning problem refer here.</li> <li>Understand configuration spaces from this video.</li> </ol>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/","title":"Probabilistic Roadmaps","text":""},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#introduction","title":"Introduction","text":"<p>The probabilistic roadmap method is a fairly simple sampling based path planning method, compared to the other sampling based algorithms, RRT and RRT*. It was introduced in the paper titled Probabilistic Roadmaps for Path Planning in High-Dimensional Configuration Spaces, and the invention of the PRM method is credited to Lydia E. Kavraki.</p> <p>As this is a sampling based algorithm, it involves randomly sampling points in a given space.</p> <p> Source: Wikipedia</p> <p>This algorithm is divided into two phases, namely, the learning phase and the query phase.</p> <ul> <li> <p>In the learning phase, the roadmap containing nodes and edges is generated. These nodes and edges are entirely inside the search space and do not overlap with obstacles.</p> </li> <li> <p>In the query phase, graph based algorithms, like A* and Dijkstra\u2019s algorithms, are used on the probabilistic roadmap to find the optimal path.</p> </li> </ul> <p>It is important to first get an intuition of the algorithm before moving on to the pseudocode. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#how-it-works","title":"How it works","text":""},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#learning-phase","title":"Learning Phase","text":"<p>The robot in question can only take certain configurations and positions in a given space. The set of all these configurations is called the configuration space or C-space.</p> <p>In a given space, the first step is to randomly generate a point. It is then checked whether this point is in C-space or not.</p> <p>If it is in C-space, we add this point to the graph by connecting it to all the points in the graph that are within a specific radius from the generated point by a straight line. It also checks whether this line is in free space, and only forms this connection if it is.</p> <p></p> <p>Source: Mathematical Problems in Engineering</p> <p>In the above diagram, a node \\(q_i\\) was randomly generated. Nodes within the radius \\(r_{\\eta}\\) are searched for and connected to \\(q_i\\) through edges.</p> <p>This process is then repeated as many times as necessary. As the number of samples tends to infinity, the likelihood that the graph is a true road map tends to 100%.</p> <p>Once this is done, we add the start node and the goal node by joining a line from each of the two to the closest node in the graph to each of them. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#query-phase","title":"Query Phase","text":"<p>This phase involves using the nodes of the roadmap generated in the learning phase as points on a graph and use graph based algorithms like A* and Dijkstra to come up with an optimal path for the robot to take.</p> <p>Given the start and goal configurations, \\(s\\) and \\(g\\), the method tries to connect them to two nodes \\(\\tilde{s}\\) and \\(\\tilde{g}\\) in the graph. If succesful, the method tries to find the optimal path from \\(s\\) to \\(g\\) using graph based algorithms.</p> <p>We have already covered graph based algorithms separately so you can refer to those for how they work.</p> <p>Figure: Optimal path generated using some graph based algorithm on the roadmap. (Courtesy: Yogesh Girdhar)</p> <p>One interesting thing to note is that the learning phase and query phase can be interwoven, i.e., the two phases don\u2019t need to be carried out sequentially.</p> <p>For example, we might first create a small roadmap and then apply graph based algorithms on it. We might simultaneously perform the learning phase and connect new nodes generated to the path to create a more optimal path as both phases are being carried out simultaneously.</p> <p>For this section, however, we will assume the learning phase has been carried out before performing query phase.</p> <p>Let\u2019s now look at the pseudocode that describes the algorithm. The functions used in the pseudocode are explained in our page on the RRT* algorithm, under the section \u201cFunctions used in Pseudocode\u201d. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#pseudocode","title":"Pseudocode","text":"<p>The following pseudocode only performs the learning phase for the PRM algorithm. The query phase has not been included in the pseudocode.</p> <pre><code>def PRM(n, r, x_init, x_goal):\n    V = []\n    E = []\n    for i in range(n):\n        x_rand = SampleFree()\n        U = Near(V, E, x_rand, r)\n        V.append(x_rand)\n        U.Sort(distance(x_rand))\n        for u in U:\n            if [[x_rand, u], [u, x_rand]] not in E:\n                if CollisionFree(x_rand, u):\n                    E.append([[x_rand, u], [u, x_rand]])\n\n    return V, E\n</code></pre> <p>In this psuedocode, the function <code>U.Sort(distance(x_rand))</code> sorts the list <code>U</code> according to the Euclidean distance between each element of the list and <code>x_rand</code>, in increasing order. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/PRM/#references","title":"References","text":"<ol> <li>The original paper on PRM.</li> <li>You can watch this video for a brief explanation.</li> <li>Refer this video to code this algorithm on MATLAB.</li> </ol>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/","title":"Rapidly Exploring Random Trees","text":""},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#salient-features","title":"Salient Features","text":"<ol> <li>Randomly samples nodes in the Configuration space of the robot to build a tree of valid configurations.</li> <li>It is Probabilistically Complete,having the probability to find a solution if it exists. In worst case, time taken to find a solution can be very long (longer than exhaustive search). The probability of finding a solution goes to \\(1\\) as number of sampled nodes goes to \\(\\infty\\).</li> <li>In practise, the algorithm tends to be very effecitve in high dimensional spaces.</li> <li>There is no gaurantee regarding the optimality of the solution. The path produced my bot the the shortest path.</li> <li>Post processing of the path generated is required as the path generated is often very unordered or in zig-zag fashion.</li> </ol>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#intuition","title":"Intuition","text":"<p>The basic idea behind the algorithm is to start out at a start node and to generate random points in the configuration space and the tree is extended by connecting the randomly generated point to the closest node in the existing tree available.</p> <p>There are a few key things to note here. Firstly, the points aren\u2019t joined directly. We take a maximum distance between sampled node and nearest node (called <code>DELTA</code> in the pseudocode). We extend the nearest node by this distance towards the randomly sampled node, if the sampled node is farther than this distance. Otherwise, if the sampled node is closer than this value, we directly connect the two nodes.</p> <p></p> <p>Courtesy: Joon\u2019s Lectures</p> <p>In the above image, \\(q_{rand}\\) is the randomly sampled point, \\(q_{nearest}\\) is the nearest (to \\(q_{rand}\\)) point in the tree. Since the distance between \\(q_{rand}\\) and \\(q_{nearest}\\) is greater than the maximum distance \\(v\\), we connect \\(q_{nearest}\\) to \\(q_{new}\\), which is at a distance of \\(v\\) from \\(q_{nearest}\\).</p> <p>This process is continuously carried out for many iterations until the goal is reached. The tree expands rapidly, and hence the name.</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#collision-checking-function","title":"Collision Checking Function","text":"<p>One important requirement of sampling algorithms, is the ability to check if a configuration is valid or not. To check if a configuration \\(X\\) is valid in a configuration free space \\(\\mathbb{C}\\), a function as such can be used:</p> \\[     CollisionCheck(X) = \\begin{cases}                                 0 \\quad &amp;\\text{if} \\, X \\in \\mathbb{C} \\\\                                 1 \\quad &amp;\\text{if} \\, X \\notin \\mathbb{C}                         \\end{cases} \\\\ \\]"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#psuedo-code","title":"Psuedo Code","text":"<pre><code>def RRT(START, GOAL):\n    TREE = []\n    TREE.add(START)\n    DELTA = maximum distance between sampled node and nearest node. \n    REPEAT n times:\n        X = generateNewConfiguration()\n        if X in FREE_SPACE:\n            for nodes in TREE:\n                Y = argmin(nodes, criteria=distance)\n            if DIST(X, Y) &lt; DELTA:\n                Find a configuration Z that is at DELTA distance along the path from X to Y\n                if TRAVERSABLE(X, Z):\n                    X.parent = Y\n                    TREE.add(X)\n            else:\n                if TRAVERSABLE(X, Y):\n                    X.parent = Y\n                    TREE.add(X)\n            if X is GOAL:\n                report \"SUCCESS\"\n                break\n</code></pre>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#notations-and-functions-used-in-psuedo-code","title":"Notations and Functions used in Psuedo Code:","text":"<ul> <li>Function used to check if a path is traversable:</li> </ul> \\[     Traversable(X, Y) = \\begin{cases}                         1 \\quad &amp;\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\in \\mathbb{C} \\\\                         0 \\quad &amp;\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\notin \\mathbb{C} \\\\                         \\end{cases} \\] <ul> <li>In case of Rotations:</li> </ul> \\[     Dist(X, Y) = \\min{(\\lvert X_n - Y_n \\rvert}, \\lvert\\ 2\\pi - \\lvert X_n - Y_n \\rvert \\rvert)  \\]"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT/#references","title":"References","text":"<ol> <li>Refer this article for more information about RRT and RRT*</li> <li>A video explaining RRT algorithm.</li> <li>Refer to the paper here</li> </ol>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/","title":"Optimal Rapidly Exploring Random Trees (RRT*)","text":"<p>In the year 2011, Sertac Karaman and Emilio Frazzoli in their paper Sampling-based Algorithms for Optimal Motion Planning, introduced three new path planning algorithms that improved upon the existing algorithms. These were, namely, optimal rapidly exploring random trees (RRT*), optimal probabilistic road mapping (PRM*), and rapidly exploring random graphs (RRG).</p> <p>The most popular algorithm among these is the RRT* algorithm, that is heavily based on the RRT algorithm, and has some improvisions, and provides a more optimal solution.</p> <p>Let\u2019s now look at the RRT* algorithm that was originally proposed in the paper along with the pseudo code. All the mathematical notations and functions in the paper are clearly explained here.</p> <p>The following image shows the RRT* algorithm applied on a 2D graph.</p> <p> Courtesy: SAI VEMPRALA </p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#intuition","title":"Intuition","text":"<p>The node sampling and selection process is exactly the same as RRT, wherein a point is randomly generated and a node is created at that point or at a specified maximum distance from the existing node, whichever is closer.</p> <p>However, the difference is where the connection is made. We assign every node a cost function that denotes the length of the shortest path from the start node. We then search for nodes inside a circle of given radius r centred at the newly sampled point.</p> <p>We then rearrange the connections such that they minimize the cost function and optimize the path. This can rearrange the graph in such a way that we get the shortest path.</p> <p> Courtesy: Joon\u2019s lectures</p> <p>In the image above, after rearranging the connections, the path to the green points, i.e., \\(q_{near}\\) is shorter through the red connections than through the earlier connections. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#pseudocode","title":"Pseudocode","text":"<p>The following is the pseudocode for the RRT* algorithm. An explanation of all the unique functions used in the pseudocode is explained below.</p> <pre><code>def RRT_Star(V, E, r, c):\n    V = [x_init]\n    E = []\n    # G = (V, E)\n    for i in range(1, n):\n        x_rand = SampleFree()\n        x_nearest = Nearest(V, E, x_rand)\n        x_new = Steer(x_nearest, x_rand)\n        if ObstacleFree(x_nearest, x_new):\n            X_near = Near(V, E, x_new, r)\n            # list of all nodes at radius r\n            V.append(x_new)\n            x_min = x_nearest\n            c_min = cost(x_nearest) + c(Line(x_nearest, x_new))\n            # the cost of the nearest node to new node\n            # to check whether to change paths\n\n            for x_near in X_near:\n                if CollisionFree(x_near, x_new)*Cost(x_near)+c(Line(x_near, x_new)) &lt; c_min:\n                    x_min = x_near\n                    c_min = Cost(x_near) + c(Line(x_near, x_new))\n                    # update c_min, because we now need to find nodes that are closer than this new x_new\n\n            E.append([x_min, x_new])\n\n            for x_near in X_near:\n                if CollisionFree(x_new, x_near)*Cost(x_new) + c(Line(x_new, x_near)) &lt; Cost(x_near):\n                    x_parent = Parent(x_near)\n                    E.remove([x_parent, x_near])\n                    E.append([x_new, x_near])\n                    # remove all edges between nodes (in radius r) and their parents and join them with x_new\n                    # this is the step of reconnection of edges\n    return V, E\n</code></pre> <p> </p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#functions-used-in-pseudocode","title":"Functions used in Pseudocode","text":""},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#samplefree","title":"<code>SampleFree()</code>","text":"<p>The function <code>SampleFree()</code> is used to return a randomly sampled node. The samples are generally assumed to be drawn from a uniform distribution.</p> <p>Suppose the set of sample space is given as \\(\\Omega\\) and for each \\(\\omega \\in \\Omega\\),</p> <p>\\(SampleFree:\\omega \\mapsto \\{SampleFree_i(\\omega)\\}_{i\\in \\mathbb{N}_0} \\subset \\mathcal{X_{free}}\\)</p> <p>is a map from \\(\\Omega\\) to a sequence of points \\(\\mathcal{X_{free}}\\), which is the obstacle-free space.</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#nearest","title":"<code>Nearest()</code>","text":"<p>This function is used to return the nearest node in the graph. </p> <p>Let\u2019s say that our tree is a graph \\(G=(V,E)\\) where \\(V\\) and \\(E\\) are sets of vertices and edges of our tree, where \\(V\\subset \\mathcal{X}\\). We take a point \\(x\\in \\mathcal{X}\\) such that the function \\(Nearest:(G,x)\\mapsto v \\in V\\) returns the node \\(v\\) in \\(V\\) that is closest to the point \\(x\\) in terms of a distance function, such as Euclidean distance, i.e.,</p> <p>\\(Nearest(G=(V,E),x):= argmin_{v \\in V} ||x-v||\\)</p> <p>where \\(argmin_{v \\in V} ||x-v||\\) means that the value \\(v\\) in \\(V\\) is returned such that the distance \\(||x-v||\\) is minimum.</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#near","title":"<code>Near()</code>","text":"<p>This function is used to find the nodes in the graph in a fixed radius in order to rearrange the connections such that we get the optimal path.</p> <p>Let\u2019s say the radius is \\(r\\) such that \\(r\\in \\mathbb{R}\\). The function \\(Near:(G,x,r)\\mapsto V'\\subseteq V\\) returns the vertices \\(V'\\) in \\(V\\) that are contained in a circle of radius \\(r\\) centred \\(x\\), i.e.,</p> <p>\\(Near(G=(V,E),x,r):=\\{v\\in V:v\\in \\mathfrak{B}_{x,r}\\}\\)</p> <p>where \\(\\mathfrak{B}_{x,r}\\) is the set of all points within the fixed radius \\(r\\) centred at \\(x\\).</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#steer","title":"<code>Steer()</code>","text":"<p>This function is the one that creates a new node that is at a maximal distance from the nearest node in the direction of the sampled node (or it\u2019s equal to the sampled node itself, if it\u2019s closer than this distance).</p> <p>Suppose we have two points \\(x,y\\in \\mathcal{X}\\). The function \\(Steer:(x,y)\\mapsto z\\) returns a point \\(z \\in \\mathcal{X}\\) such that \\(z\\) is closer to \\(y\\) than \\(x\\) is. This will be such that \\(z\\) minimizes the distance \\(||z-y||\\) and at the same time maintains the distance \\(||z-x||\\leq\\eta\\) for the predefined maximal distance \\(\\eta &gt; 0\\), i.e.,</p> <p>\\(Steer(x,y):=argmin_{z\\in \\mathfrak{B}_{x,\\eta}}||z-y||\\)</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#line","title":"<code>Line()</code>","text":"<p>The <code>Line()</code> function is used to denote a straight line, i.e., given two points \\(x_1,x_2\\in \\mathbb{R}^d\\),</p> <p>\\(Line(x_1,x_2):[0,s]\\mapsto\\mathcal{X}\\)</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#parent","title":"<code>Parent()</code>","text":"<p>The <code>Parent()</code> function is used to denote the parent node of a given node in a tree, i.e., given a tree \\(G=(V,E)\\), \\(Parent:V\\mapsto V\\) is a function that maps a vertex \\(v\\in V\\) to the unique vertex \\(u\\in V\\) such that \\((u,v)\\in E\\).</p> <p>Note that if \\(v_0 \\in V\\) is the start node of \\(G\\), then, by convention, \\(Parent(v_0)=v_0\\).</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#cost","title":"<code>Cost()</code>","text":"<p>This is function that makes RRT* different from RRT. As mentioned before, we assign each node a cost that is a function of the distance along the path from the start node. It\u2019s given as follows.If \\(Cost:V\\mapsto \\mathbb{R}^+\\) is a function that maps the vertex \\(v_0\\mapsto V\\) to the cost of the unique path from the root of the tree to \\(v\\), then</p> <p>\\(Cost(v)=Cost(Parent(v))+c(Line(Parent(v),v))\\)</p> <p>where \\(c\\) is a function that transforms the length value of the \\(Line\\) into a cost</p> <p>Note that if \\(v_0\\) is the start node or root vertex of \\(G\\), then, by convention, \\(Cost(v_0)=0\\).</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#collisionfree","title":"<code>CollisionFree()</code>","text":"<p><code>CollisionFree(x,x')</code> returns <code>True</code> if the line segment joining x and x\u2019 lies in \\(\\mathcal{X_{free}}\\), where \\(x,x'\\in \\mathcal{X}\\) and <code>False</code> otherwise. \u00a0</p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#visual-comparison-between-rrt-and-rrt","title":"Visual comparison between RRT and RRT*","text":"<p>The following image shows the RRT and RRT* algorithms applied on a 2D graph with obstacles. The plot on the left is RRT and the plot on the right is RRT*. As one can see, the RRT* algorithm provides a more optimal solution to the path planning problem.</p> <p> Courtesy: Andr\u00e1s Gyimesi </p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#a-flowchart-summary-of-the-rrt-algorithm","title":"A flowchart summary of the RRT* algorithm","text":"<p>The following flowchart provides a visual summary of the optimal rapidly exploring random trees algorithm.</p> <p> Courtesy: Nir Rikovitch </p>"},{"location":"automation/PathPlanners/Sampling_Based_Algorithms/RRT_Star/#references","title":"References","text":"<ul> <li>The paper by Karaman and Frazzoli.</li> <li>Refer this article for a synopsis.</li> <li>Watch this video and this video for visualization of the algorithm.</li> </ul>"},{"location":"automation/ROS/ros/","title":"Getting Started with Robot Operating System (ROS)\u201d","text":""},{"location":"automation/ROS/ros/#1-what-is-ros","title":"1. What is ROS?","text":"<p>For someone completely new to ROS, the best way to think about it is a collection of tools and frameworks which make automating robotics projects much easier. Every ROS project has a certain structure which you have to follow. Your job would be to fill in the automation code along defining how the different parts of your code are communicating with one another. Once this is done, the underlying ROS framework takes care of the actual networking and connections.</p> <p>ROS also has the advantage of having a large open source community with tons of packages. This means you have a lot of prewritten code to help with your project and you don\u2019t have to start from scratch.</p> <p>Don\u2019t worry if you are still confused, you will start to get a better understanding with some hands on experience. \u200bTo get a better understanding of what ROS is and why it exists, checkout out these videos (\u200b1 \u200b, 2).</p> <p></p> <p>A ROS system can be visualized as a graph where all the vertices are \u200bnodes and the edges between them are known as \u200btopics. In simple terms nodes are programs that perform a particular task and send out/receive data in the form of messages. These messages are exchanged between two nodes over the topic (edge) connecting them. An example of a typical ROS system is given in the figure to the left wherein \u201crobot\u201d, \u201claser\u201d, \u201cmap\u201d, \u201clocalisation\u201d and \u201cplanner\u201d are the nodes and the arrows connecting the nodes are the topics. An arrow \u200bfrom A to B indicates that the topic carries messages from node \u200bA to node B.</p>"},{"location":"automation/ROS/ros/#2-reference-material","title":"2. Reference Material","text":"<p>While we have tried our best to provide a concise introduction to the basic concepts in this document, there are a lot of other much more thorough and complete resources that you should follow. This document can be treated more as a reference guide with some useful tips for beginners.</p> <p>The two most useful resources you can go through are -</p> <ul> <li>Programming Robots with ROS :\u200b A Practical Introduction to the Robot Operating System by Morgan Quigley.</li> <li>ROSwiki\u200b tutorials : The official ROS tutorials.</li> </ul> <p>Both of these have detailed implementation guides on the basic concepts. The ROSwiki is more concise while the book goes into more detail. We strongly recommend that you go through the first 4 chapters of the book and try out all the implementation examples yourselves. Along with these you can check out The Construct youtube \u200bvideos\u200b.</p>"},{"location":"automation/ROS/ros/#3-basic-concepts","title":"3. Basic Concepts","text":"<p>Now let\u2019s get familiar with some very commonly used terms in ROS development. Along with the following introduction you should go through \u200b Chapter 1 and 2\u200b of Morgan Quigley for in depth explanation and examples.</p> <p>Catkin: Catkin is the build system used for ROS. This means that after you have written all your code, defined your message files etc, you will run catkin to join everything together and compile any dependencies you have. To build packages you must have a catkin workspace where all your projects are contained. You will have to use it to \u200b build \u200b not only yours but any other packages that may be in your workspace. Click \u200bhere\u200b to learn more about catkin. A catkin workspace or package can be built running either of these two commands : <code>catkin_make</code> or <code>catkin build</code> in the root of your catkin workspace.</p> <p>Note : The command used for building a workspace should be consistent everytime, i.e. if the workspace was built using catkin_make the very first time while initializing the workspace, all the subsequent builds should be done using catkin_make. To change the method of build in a pre existing workspace, you can use the command <code>catkin clean</code> which will clear everything except the source space (src folder) of the workspace. It can then be rebuilt using the desired command.</p> <p>Colcon: Colcon is another build system just like catkin. It comes with a vast array of features which can be used to organise your workspace. Similar to catkin, to build a workspace, you need to run <code>colcon build</code> in the root of the folder your workspace. You can check out the documentation of colcon to explore more features.</p> <p>Workspace: \u200bA ROS workspace is basically a directory with a certain hierarchy wherein all your sets of related ROS codes live. A workspace contains packages which in turn contain the code for nodes amongst other things. You can have multiple workspaces on your computer but work in only one at a time. Follow this\u200b tutorial in order to set up your own catkin workspace. After following the steps in the above tutorial, upon entering your workspace directory, you will see three directories: \u200bbuild, \u200bdevel \u200band \u200bsrc.</p> <p>ROS Package: \u200b All the codes and software in ROS is organised in the form of packages. A package may contain ROS Nodes, libraries used in those codes, message and service definitions and all the dependencies. Follow \u200bthis\u200b tutorial to know how to create a ROS package. (Note: Follow the \u2018catkin\u2019 way instead of \u2018rosbuild\u2019). After creating the package you\u2019ll see two files \u200bCMakeLists.txt and package.xml. We\u2019ll be using (editing) these files many times as we proceed to work with ROS. Apart from these files there is a directory \u201csrc\u201d. This is the place where the code for ROS nodes of the package lives (as mentioned before, nodes are nothing but programs that perform specific tasks). Once you have created your ROS package you have to build it so that you can use it. Follow \u200bthis\u200b tutorial to see how to build your package.</p> <p>ROS Nodes and Packages: A \u200bnode is an executable file (could be python or C++) which performs a specific task and communicates with other nodes through \u200b topics. \u200bTwo main ways this is done is through publisher-subscriber relationship or services. All of the programming involved in creating a ROS based project is done while writing these nodes.</p> <p>Topics are\u200b the channels over which the messages of different kinds are transmitted between nodes, read \u200bthis\u200b wiki to know more. ROS messages have to be specially defined for each user defined topic. Apart from the standard message types that come with ROS like \u200bstring, int32, etc. you can also define your custom message types in ROS for custom uses. Refer to parts 2 and 3 this\u200b tutorial to see how you can define and use a custom message type.</p> <p>Note: A single node can simultaneously act as a subscriber to one topic and a publisher of another topic and a server for one service and the client for another.</p> <p>Publisher - Subscriber Model: \u200bThis is a model through which two nodes can exchange data in the form of messages asynchronously, usually used when a one way stream of information is involved.</p> <p>For example, suppose you are developing a self-driving car and you have a node which processes the video feed from a camera to detect street signs. Whenever it detects a sign, it needs to communicate its type and distance from the car to another node which will use this information to control the speed of the car. In this scenario your sign detection node will be a publisher which publishes data about the signs it detects to a specific topic, say signs. \u200bYour controller node will be a subscriber which will subscribe to the \u200b signs \u200b topic and perform a certain task whenever it receives a message on this topic.</p> <ul> <li>Publisher: The publisher object of a ROS node publishes the data in the form of messages over a topic. There is a particular rate (which the user defines) at which the messages get published.</li> <li>Subscriber: The data published by the publisher of one ROS node can be received or \u2018subscribed\u2019 through the Subscriber object of a ROS node. The Subscriber object subscribes to the topic over which any publisher publishes the messages. Every Subscriber object is associated with a callback function which gets called everytime a message is published over the topic.</li> </ul> <p>You can check out how to implement a basic server-client for C++\u200b or \u200bpytho\u200bn in the ROS wiki or \u200bChapter 3\u200b of Morgan Quigley.</p> <p>Services:  Another common mode of communication, especially suited when there is a transaction style relationship between the two nodes is the service - consisting of a server and a client.</p> <p>For example consider in your self driving car, you have one node to control the movement of the car and another to plan an optimal route to your destination. In such a scenario, the main control node would be the \u200bclient \u200bfor the route planning \u200b server. This means that whenever the controller requires a route to be planned, supposed it finds out the route is blocked up ahead, then it would send a request to the server. This request would consist of the current location, the destination as well as any preferences the controller might have (like faster/more comfortable). The server would then compute an optimal route and return it to the client as the response.</p> <ul> <li>Client: \u200bThis is the node which sends requests to a server. In the client code, you can create a special function which acts as a proxy between the client and server. Whenever you call the function, it sends a request to the server with the arguments passed to it as parameters.</li> <li>Server: \u200bThis node constantly monitors for requests from the client. Whenever it receives one, it carries out the required task independently of the client and sends back the response when the task is complete.</li> </ul> <p>You can check out how to implement a basic server-client for C++\u200b or \u200bpython\u200b in the ROS wiki or Chapter 4\u200b of Morgan Quigley.</p>"},{"location":"automation/ROS/ros/#4-getting-things-running","title":"4. Getting things running","text":"<p>Getting a complete ROS system up and running requires a bit more work than executing a single file. Check out \u200bChapter 20 of Morgan Quigley for more detailed explanation as well as examples for all of the following tools.</p> <p>ROS Master: Before running the functional nodes in your system, you should first understand ROS Master. This can be visualised as a central server to which all nodes are connected by default. It allows any node to look up information about any other node. This is essential for connecting nodes within the system. For eg. when a node (A) needs to subscribe to a topic published by another node (B), it will get the network address of node B from ROS Master.</p> <p>As you might guess, a running ROS Master is necessary for every ROS system since, without it, the nodes won\u2019t be able to connect with each other. Thus whenever you are setting up your system of nodes the first command must run in the terminal is \u200b roscore which initializes ROS Master. The ROS wiki has a section on ROS Master \u200bhere\u200b or you can check out\u200b Chapter 2 \u200bof Morgan Quigley.</p> <p>rosrun: Once you start the ROS Master, you can now start your own ROS nodes. For this ROS has a special command called  rosrun which lets you run the executable files for your node from anywhere. The format for rosrun is -</p> <pre><code>rosrun &lt;package_name&gt; &lt;executable_name&gt;.py\n</code></pre> <p>(Replace  and  appropriately) <p>A note on node file permissions: If using python, before attempting to run any ROS nodes that you have written, make sure that you have given executable permission to the code files. For more info on linux file permission look \u200bhere\u200b. The command to do this is -</p> <pre><code>chmod u+x &lt;executable_name&gt;.py\n</code></pre> <p>(Replace  appropriately) <p>A note on multiple terminal windows: Whenever you run \u200b roscore\u200b or your own ROS node, it will hold the terminal until it is killed. So if you are running multiple nodes, you will need to run each one in a separate terminal window (\u200bterminator\u200b to your rescue!).</p> <p>A note on the tab key in terminal:* Typing out long commands into the terminal can get tedious. So ros has a handy capability of completing your commands for you. Whenever you are using \u200b rosrun\u200b or roslaunch\u200b, you can type out the first few letters in the package name and then press the Tab key* on your keyboard. At this point, the package name will be autocomplete, saving you a lot of typing. Try it out, this works with other terminal commands too!</p> <p>roslaunch: ROS projects can involve a lot of nodes and launching them one by one can be a hassle. roslaunch is a command which lets you launch a specific set of nodes at once in a single terminal by using  launch-files. These files usually contain a list of nodes and other related info and are generally stored in the \u2018launch\u2019 directory inside a package. Follow this tutorial to learn how to make a launch file.</p> <p>roscd: roscd is a command line tool which allows you to navigate or \u2018cd\u2019 (change directory) to (in command line terms) a package without knowing its exact path. Note: The workspace in which the package is present needs to be sourced. E.g. If you wish to navigate into the \u2018turtlebot3_gazebo\u2019 package you\u2019ll just type the following command in the terminal:</p> <pre><code>roscd turtlebot3_gazebo\n</code></pre> <p>rqt_graph: Once you have your system running, you can obtain a diagram along with other details of the system by running the  rqt_graph command in another terminal window.</p>"},{"location":"automation/ROS/ros_p2/","title":"ROS Parameters","text":""},{"location":"automation/ROS/ros_p2/#ros-parameters-and-parameter-server","title":"ROS Parameters and Parameter Server","text":"<p>Parameter server is a collection of values or parameters that can be retrieved or modified by the nodes during runtime upon requests through command prompt, nodes or launch files. Parameters are intended to be static, globally available values like integers, floats, strings and boolean values and can be stored independently or within a YAML file. Parameters are meant to be gloablly viewable so nodes can easily inspect the configuration state of the system and modify if necessary.</p>"},{"location":"automation/ROS/ros_p2/#accessing-and-setting-parameters","title":"Accessing and setting Parameters","text":""},{"location":"automation/ROS/ros_p2/#via-command-line","title":"Via command line","text":"<p>Parameters can be accessed, modified or deleted using the <code>rosparam</code> command line utility in the <code>rosbash</code> suite of terminal commands. 1) To list all the parameters :  <code>rosparam list</code></p> <p>Or to list all the parameters in a specific namespace :  <code>rosparam list &lt;/namespace&gt;</code></p> <p>2) To assign a value to an already existing parameter or to set a new one :  <code>rosparam set &lt;parameter_name&gt; &lt;parameter_value&gt;</code></p> <pre><code>Note : You can also load the parameters into the parameter server from a YAML file using &lt;br/&gt;\n```rosparam load &lt;filename&gt; &lt;namepsace&gt;```\n</code></pre> <p>3) To get/read a parameter value :  <code>rosparam get &lt;parameter_name&gt;</code></p> <p>Note : You can also dump/save the parameters into a YAML file from parameter server using  <code>rosparam dump &lt;filename&gt; &lt;namespace&gt;</code></p> <p>For more insights regarding the <code>rosparam</code> tool refer to this link.   </p>"},{"location":"automation/ROS/ros_p2/#via-the-rospy-api-library","title":"Via the rospy API library","text":"<p>Parameters from the parameter server can be accessed and modified using <code>rospy</code> API library. This is generally used when the parameters are to be used by a node during the runtime. Refer this link for more imformation on handling parameters using <code>rospy</code> API library.</p>"},{"location":"automation/ROS/ros_p2/#via-launch-files","title":"Via launch files","text":"<p>Parameters can be set, created and loaded into the parameter server while creating launch files. Refer to this link ROSWiki for more information on handling parameters in launch files.</p> <p>Following links can be referred to for more insights on parameters and parameter server 1, 2, 3</p>"},{"location":"automation/ROS/setting_up/","title":"Preparing your Development Environment","text":"<p>One of the most essential and widely used tools for robot automation in Robot Operating System or ROS. This section will guide you through how to setup ROS and other tools on your computer.</p>"},{"location":"automation/ROS/setting_up/#1-operating-system","title":"1. Operating System","text":"<p>Robotics Development relies heavily on  Linux . We recommend using  Ubuntu 18.04 since it is the most widely used and supported variant of Linux. If you already have Ubuntu 16.04, this is also OK, although for versions older than this we recommend upgrading to 18.04.</p> <p>For those who currently have Windows as the only OS on their machine, the best way to start using Ubuntu would be to dual boot. Here is a guide on how to do this . For MacOS users, dual booting is an  option but we recommend using up a virtual machine.</p> <p>If you are unable to dual boot for any reason, you can try setting up a virtual machine. The first step in this is to install a virtualisation software. For Windows you can use either VirtualBox (free) or Vmware Workstation and for MacOS either VirtualBox (free), Vmware Fusion or Parallels. After getting one of the above, follow the instructions given here (skip ahead to the Download Image section). After completing the given procedure you will be equipped with all the basic tools required for Robotics including ROS, catkin and git.</p> <p>In the unfortunate case that the above options do not work, for Windows users there is still a way - WSL. Do be warned however, this path is fraught with frustration and much debugging. Only continue if you have exhausted other options. For a guide on setting up WSL for ROS, look here. </p> <p>For those whom none of the above are possible, consider using the online browser based ROS Development Studio. Keep in mind that it has a limited access time per week and performance may be questionable.</p>"},{"location":"automation/ROS/setting_up/#2-robot-operating-system-ros","title":"2. Robot Operating System (ROS)","text":"<p>Note that this part is unnecessary if you followed the given instructions to set up a VM. For everyone else, this part is essential. Different versions of Ubuntu need different variants of ROS. Instructions given below -</p> <p>\u2794 Ubuntu 18.04 :  ROS Melodic  \u2794 Ubuntu 16.04 :  ROS Kinetic</p>"},{"location":"automation/ROS/setting_up/#3-useful-tools-to-make-your-life-easier","title":"3. Useful tools to make your life easier","text":"<ul> <li>Git\u200b : Fundamental tool in open source software development. Used for version control and sharing of code.</li> </ul> <pre><code>    sudo apt install git\n</code></pre> <ul> <li>Terminator\u200b : Terminal Emulator useful for having multiple terminals in a window.</li> </ul> <pre><code>    sudo apt install terminator </code></pre> <ul> <li>Code Editors : A good editor can go a long way in boosting productivity. We recommend \u200bVSCode\u200b which has plugins for python and ROS. A comprehensive guide for how to integrate ROS into your favourite IDE can be found \u200bhere\u200b.</li> </ul>"},{"location":"automation/ROS/setting_up/#4-ros-packages","title":"4. ROS Packages","text":"<ul> <li>You can install already developed ROS packages using the apt (package manager for Ubuntu). Replace  name of the ROS package <pre><code>    sudo apt install ros-$ROS_DISTRO-&lt;package_name&gt;\n</code></pre> <ul> <li>For example Turtlebot is one of the most commonly used ground bots for simulation purposes. You can install Turtlebot and it\u2019s related packages using the following command -</li> </ul> <pre><code>    sudo apt install ros-$ROS_DISTRO-turtlebot3-*\n</code></pre>"},{"location":"automation/ROS/setting_up/#5-tips-for-getting-things-to-work-some-helpful-facts","title":"5. Tips for getting things to work + some helpful facts","text":"<ul> <li> <p>Make a habit of running  sudo apt update before installing packages in linux.</p> </li> <li> <p>For the uninitiated, your  bashrc  file is the configuration file for your bash terminal (the thing you type commands into). It\u2019s usually located in your home directory at ~/.bashrc  For more info, check out this.</p> </li> <li> <p>Don\u2019t forget to source the workspace you want to use. For convenience you can source the workspace on startup by editing your .bashrc file to include the following line. Replace  with the path of your workspace <pre><code>    source &lt;workspace_path&gt;/devel/setup.bash\n</code></pre> <ul> <li> <p>You cannot source two workspaces at the same time.</p> </li> <li> <p>Anaconda and ROS cannot be used in the same environment because they have a conflicting python path. As given  here , to deal with this, edit your bashrc  file by commenting the anaconda python path like this -</p> </li> </ul> <pre><code>    //  export PATH=\"/home//anaconda3/bin:$PATH \"\n</code></pre> <ul> <li>Use python  pip to install python dependencies. Anaconda should be avoided.</li> </ul>"},{"location":"electronics/intro/","title":"Introduction","text":"<p>From interfacing microprocessors to making logical circuits, Robotics is incomplete without electronics. Every task that a Robot performs at the end eventually boils down to some signal received by it.  Electronics for any robotics projects involves tasks like setting up the power source, interfacing sensors, setting up the computation unit, etc. </p> <p>Most of the Robots have a processing unit on them which collects data from sensors and peforms all the calculations for determining the steps that the robot needs to peform. Some of the popular processing units used for robots are Raspberry Pi, Nvidia Jetson, Arduino, etc.</p> <p>Sensors are the medium through which any robot interacts with its environment. Some of the common sensor we can see in robots are depth cameras, LIDAR, Encoders, IMU, etc.</p>"},{"location":"electronics/Basic_Electronic_Components/breadboard/","title":"Breadboards","text":"<p>The breadboard is the most fundamental tool for electronics prototyping. They are great for creating temporary circuits and require absolutely no soldering.</p> <p></p>"},{"location":"electronics/Basic_Electronic_Components/breadboard/#how-to-use-a-breadboard","title":"How to use a breadboard","text":"<p>A solderless breadboard consists of several holes, where wires or leads of electrical can be inserted. Each row of 5 holes is electrically connected by metal clips hidden underneath the surface.</p> <p></p> <p>Thus, one can connect two components by inserting them into holes of the same row. ICs can be inserted across the central ridge, and connections made as shown below.</p> <p></p> <p>On either side of the breadboard are the power rails. Each power rail has two long electrically connected rows, and are often connected to batteries or some other power source.</p> <p>For a more extensive breadboard tutorial, check out this sparkfun guide.</p>"},{"location":"electronics/Basic_Electronic_Components/breadboard/#tips-for-breadboard-usage","title":"Tips for breadboard usage","text":"<ol> <li> <p>To make breadboard connections, DuPont style jumper wires or single core 22AWG wire is most convenient. Avoid multistranded wire.</p> </li> <li> <p>Keep wires and wire leads as short as possible, to avoid clutter and make troubleshooting easier.</p> </li> </ol> <p></p>"},{"location":"electronics/Development_Boards/Arduino/","title":"Arduino","text":"<p>The Arduino is basically a very accessible and easy to program microcontroller. Unlike other microcontrollers, which need knowledge of registers and ports, the Arduino is programmed by a very basic C-derived language. This video explains what an Arduino is, what it is capable of, and the numerous projects one can use it for.</p>"},{"location":"electronics/Development_Boards/Arduino/#arduino-board-layout","title":"Arduino Board Layout","text":"<p>The above diagram shows an Arduino UNO board with all the parts labelled and explained below:</p> <ol> <li>USB Port: Arduino can be powered by connecting it to your computer using a USB cable. It is also used for uploading code and communicating via the serial port.</li> <li>Power Jack: Used to power an arduino directly from a wall adaptor.</li> <li>Voltage Regulator: Controls and stabilises the voltage used by the Arduino and its components.</li> <li>Crystal Oscillator: A microcontroller is a clock based device. The crystal oscillator present on the arduino generates a clock of frequency 16MHz.</li> <li>Reset controllers: Resetting the arduino board starts the execution of a program from the beginning. Arduino can be reset in 2 ways : by pressing the reset button (17) and sending a 0V signal to the RESET pin (5).</li> <li>3.3V power</li> <li>5V power</li> <li>GND (0V)</li> <li>VIN: This pin can be used to power the arduino board from an external power source, from 7-20V.</li> <li>Analog Pins: These pins (labeled A0-A5) can be used to read continuous analog values (between 0 and 5V). They are often used to interface the Arduino with analog sensors.</li> <li>Main Microcontroller: This IC is the main microcontroller, that executes the code you program it with.</li> <li>ICSP Pin: Can be used to program the arduino board\u2019s firmware. For advanced users only.</li> <li>Power LED indicator: Indicates whether the board is powered up correctly.</li> <li>TX/RX LEDs: The TX/RX pins flash to indicate transfer/receival of serial data between the computer and Arduino.</li> <li>Digital I/O Pins: \u00a0These pins can be programmed as input/output pins. When used as output, they can be set HIGH (+5V) or LOW (0V).</li> <li>Analog Reference(AREF): Can be used to set an external reference voltage(0-5V) as the upper limit for analog input pins.</li> <li>Reset Button: Pressing it causes the Arduino to restart its code.</li> </ol>"},{"location":"electronics/Development_Boards/Arduino/#the-blink-sketch","title":"The Blink Sketch","text":"<p>The Blink sketch is like the \u201cHello World\u201d program in the Arduino world. It simply consists of blinking the onboard LED (labeled \u2018L\u2019). No actual circuit connections are required!</p> <p></p>"},{"location":"electronics/Development_Boards/Arduino/#code","title":"Code","text":"<p>You can copy the code from here.</p>"},{"location":"electronics/Development_Boards/Arduino/#how-to-code-an-arduino-in-arduino-ide","title":"How to code an Arduino in Arduino IDE","text":"<ol> <li>Download and install Arduino Software (IDE) from here. The Integrated Development Environment (IDE) is a common coding environment for all arduino boards.</li> <li>Open the IDE and a new sketch will open up which would look like the image below. Sketch is just a name arduino uses for a program.</li> <li>Then just paste the entire code here.</li> <li>Now connect your Arduino UNO board to your PC using an A B USB cable and select the option \u201cArduino/Genuino Uno\u201d under Tools &gt; Board menu. Also make sure to select the correct port through which the PC is connected to the board under Tools &gt; Port menu.</li> <li>Click on the \u201ctick\u201d button in upper left corner to compile the code and check for errors. After resolving any and all errors click on the \u201carrow\u201d button next to it to upload the code to the board.</li> <li>After successful upload the Arduino Uno will start executing the code while drawing power from the PC through the USB cable.</li> </ol>"},{"location":"electronics/Development_Boards/Arduino/#explanation","title":"Explanation","text":"<p>Every Arduino sketch must have two particular functions:</p> <ol> <li>void setup()<ol> <li>The setup() function is called when a sketch starts and will only run once, after each powerup or reset of the Arduino board.</li> </ol> </li> <li>void loop()<ol> <li>This function does precisely what its name suggests, that is loops consecutively, allowing your program to change and respond. Whatever code you write inside loop() will keep running as long as the Arduino is receiving power.</li> </ol> </li> </ol> <p>Let us examine the Blink sketch now, line by line.</p> <pre><code>int led = 13;\n</code></pre> <p>This line assigns a name to the pin that the LED is attached to, i.e. pin 13.</p> <p>Then we have the setup() function, which runs only once. It includes the following line.</p> <pre><code>pinMode(led, OUTPUT);\n</code></pre> <p>This tells the Arduino to configure that pin as an output.</p> <p>Then we have the following loop() function.</p> <pre><code>void loop()\n{\ndigitalWrite(led, HIGH);  // turn the LED on (HIGH is the voltage level)\ndelay(1000);               // wait for a second\ndigitalWrite(led, LOW);    // turn the LED off by making the voltage LOW\ndelay(1000);              // wait for a second\n}\n</code></pre> <p>The digitalWrite() function tells a pin to either switch on (HIGH, or +5V) or off (LOW, or 0V).\u00a0 The delay() function tells the Arduino to wait for a specified number of milliseconds.</p>"},{"location":"electronics/Development_Boards/Arduino/#reading-analog-values","title":"Reading Analog Values","text":"<p>The following circuit reads the voltage from a potentiometer and sends it via USB to the serial port.</p>"},{"location":"electronics/Development_Boards/Arduino/#schematic","title":"Schematic","text":""},{"location":"electronics/Development_Boards/Arduino/#code_1","title":"Code","text":"<p>Copy the code from here and paste it into a new sketch in the Arduino IDE and upload the code to the board. After successful uploading open the serial monitor in the IDE by clicking on its button on top right corner. Trying varying the potentiometer\u2019s knob - you should see the stream of values of the serial monitor change.</p>"},{"location":"electronics/Development_Boards/Arduino/#explanation_1","title":"Explanation","text":"<p>Whenever the serial port is to be used, it should be initialised with the following line inside void setup(). The 9600 refers to the communication speed in bits-per-second.</p> <pre><code>Serial.begin(9600);\n</code></pre> <p>The analogRead function reads the voltage at an analog pin and linearly converts it to a value between 0 and 1023. The Serial.println() function prints a variable to the serial monitor, followed by a newline (using Serial.print() to print data without the newline). The delay(1) is to limit the amount of data printed to the serial monitor.</p>"},{"location":"electronics/Development_Boards/Arduino/#references","title":"References","text":"<ol> <li>For more lessons and material on Arduino, check out the QSTP - Introduction to Mechatronics, designed by ERC.</li> <li>For some more detailed tutorials do read the documentation of Arduino.</li> <li>For some video tutorials check out Jeremy Blum\u2019s playlist for Arduino.</li> <li>For more DIY project ideas and inspirations check out Great Scott\u2019s youtube channel.</li> <li>To read more about the projects made by people using Arduino, check out Arduino\u2019s blog as well.</li> </ol>"},{"location":"electronics/Development_Boards/ESP32/","title":"ESP32","text":""},{"location":"electronics/Development_Boards/ESP32/#introduction","title":"Introduction","text":"<p>ESP32 is a series of feature-rich MCU with integrated Wi-Fi and Bluetooth connectivity for a wide range of applications. Espressif Systems, China, produce it.ESP32 is cheap and nearly ten times faster than Arduino Uno and is a 32-bit versatile device. Developers of ESP32 IC made a small module board with edge castellations. One popular version of such a module board is called ESP-WROOM-32. It is a dual-core, 32-bit microcontroller unit, and all the cores can be controlled individually. It has integrated Wi-Fi, Bluetooth, and Bluetooth Low Energy with multiple digital and analog I/O pins.</p> <p></p>"},{"location":"electronics/Development_Boards/ESP32/#comparison-of-esp32-and-arduino-uno","title":"Comparison Of ESP32 and Arduino Uno","text":"Parameter ESP32 ARDUINO UNO Processor Xtensa dual-core ATMega328P Number of Cores 2 1 Architecture 32 bit 8 bit Operating Voltage 2.2 to 3.6V 5V CPU Frequency 160 or 240 MHz 16 MHz WiFi YES NO Bluetooth YES NO RAM 512 KB 2 KB Flash 16 MB 32 KB GPIO pins 36 14 Busses SPI,I\u00b2C,UART,I2S,CAN SPI,I\u00b2C,UART ADC Pins 18 6 DAC Pins 2 0 USB Conector Micro Type B UART 3 1 SPI 3 1 I\u00b2C 2 1"},{"location":"electronics/Development_Boards/ESP32/#pinout","title":"Pinout","text":"<p>You can refer to the manual provided by Espressif Systems to view the complete pinout in detail.</p>"},{"location":"electronics/Development_Boards/ESP32/#peripherals-and-features","title":"Peripherals and Features","text":"<p>Now that we have seen the ESP32 Pinout , let us now focus on some of the important peripherals of ESP32 and their associated pins. ESP32 Microcontroller has:</p> <ul> <li>Up to 18 12-bit Analog to Digital converters.</li> <li>2, 8-bit Digital to Analog converters.</li> <li>10 capacitive touch switch sensors.</li> <li>4 SPI channels.</li> <li>2 I\u00b2C interfaces.</li> <li>2 I2S interfaces (for digital audio).</li> <li>3 UARTs for communications.</li> <li>Up to 8 channels of IR remote control.</li> <li>Up to 16 channels of LED PWM (pulse width modulation).</li> <li>An integrated Hall-effect sensor.</li> <li>An ultra-low-power analog preamp.</li> <li> <p>An internal low-dropout regulator.</p> </li> <li> </li> <li> </li> <li> </li> <li> </li> <li> <p>DAC1 \u2014 GPIO25</p> </li> <li> <p>DAC2 \u2014 GPIO26</p> </li> <li> </li> <li> </li> <li> </li> <li> </li> </ul>"},{"location":"electronics/Development_Boards/ESP32/#gpio","title":"GPIO","text":"<p>34 pins, each pin carries out more than one function ( only one will be active). You can configure a pin as either a GPIO or an ADC or an UART in the program.ADC and DAC pins are predefined, and you have to use the manufacturer specified pins. But other functions like PWM, SPI, UART, I2C etc. can be assigned to any GPIO pin through the program.</p>"},{"location":"electronics/Development_Boards/ESP32/#rtc-gpio","title":"RTC GPIO","text":"<p>part of the RTC Low-Power subsystem. These pins can be used to wake ESP32 from a deep sleep as an external wake-up source.</p>"},{"location":"electronics/Development_Boards/ESP32/#adc","title":"ADC","text":"<p>ESP32 has two 12-bit SAR Analog to Digital Converter Modules with 8-channels and 10-channels each. So, ADC1 and ADC2 blocks combined together have 18 channels of 12-bit ADC.With 12-bit resolution, the Digital output values will be in the range of 0 \u2013 4093.</p>"},{"location":"electronics/Development_Boards/ESP32/#dac","title":"DAC","text":"<p>ESP32 Microcontroller has two independent 8-bit Digital to Analog Converter channels to convert digital values to analog voltage signals. The DAC has an internal resistor network and uses a power supply as an input reference voltage. The following two GPIO Pins are associated with DAC functionalities.</p>"},{"location":"electronics/Development_Boards/ESP32/#capacitive-touch-gpios","title":"Capacitive Touch GPIOs","text":"<p>can detect variations in capacitance on a pin due to touching or approaching the GPIO Pin with a finger or stylus. These Touch GPIOs can be used in implementing capacitive touch pads without any additional hardware.</p>"},{"location":"electronics/Development_Boards/ESP32/#spi","title":"SPI","text":"<p>three SPI blocks (SPI, HSPI and VSPI) are present in both master and slave modes. SPI is used to interface with Flash Memory. So, you have two SPI interfaces.</p>"},{"location":"electronics/Development_Boards/ESP32/#i2c","title":"I\u00b2C","text":"<p>There are two I2C interfaces in ESP32 with complete flexibility on assigning pins, i.e., SCL and SDA pins for both I2C interfaces can be assigned in the program by the user.If you are using Arduino IDE, then the default I2C pins are: SDA \u2013 GPIO21 SCL \u2013 GPIO22</p>"},{"location":"electronics/Development_Boards/ESP32/#pwm","title":"PWM","text":"<p>The PWM Controller in ESP32 has 16 independent PWM waveform channels with configurable frequency and duty cycle. The PWM waveform can be used to drive motors and LEDs. You can configure the PWM signal frequency, channel, GPIO pin and also the duty cycle.</p>"},{"location":"electronics/Development_Boards/ESP32/#how-to-program-esp32","title":"How To Program ESP32","text":"<p>One can use C++ and MicroPython to program the ESP32. It supports multiple programming environments :</p> <ul> <li>Arduino IDE</li> <li>PlatformIO IDE (VS Code)</li> <li>LUA</li> <li>MicroPython</li> <li>Espressif IDF (IoT Development Framework)</li> <li>JavaScript</li> </ul> <p>To fully utilise the features , one must use the ESP-IDF.You can chek it out in detail here.</p>"},{"location":"electronics/Development_Boards/ESP32/#using-the-arduino-ide","title":"Using the Arduino IDE","text":"<p>You can program ESP32 using the Arduino IDE. You can refer to this tutorial to understand the complete process.</p>"},{"location":"electronics/Development_Boards/ESP32/#led-blink-sketch","title":"LED Blink Sketch","text":"<p>For more examples and initial projects for practice you can refer here.</p>"},{"location":"electronics/Development_Boards/ESP32/#references","title":"References","text":"<ul> <li>Video on Introduction to ESP 32-Getting Started by DroneBot Workshop </li> <li>For more details you can refer to the website of DroneBot Workshop here.</li> <li>ESP 32 webpage by Electronics Hub </li> <li>Programming Guide to ESP 32 by Electronics Hub and OpenLab.</li> <li>Espressif Systems documentation  on ESP 32 .</li> </ul>"},{"location":"electronics/Development_Boards/Pyboard/","title":"Pyboard - MicroPython","text":"<p>MicroPython is an implementation of the Python 3 programming language which is optimized to run on many microcontrollers. It has modules to access the hardware of the microcontroller, and the code is compatible to a great extent with normal python code.</p> <p>The Pyboard is the official MicroPython microcontroller board based on a STM3F405RG microcontroller.</p> <p></p>"},{"location":"electronics/Development_Boards/Pyboard/#pyboard-board-layout","title":"Pyboard Board Layout","text":"<p>The hardware has:</p> <ol> <li>STM32F405RG microcontroller</li> <li>168 MHz Cortex M4 CPU with hardware floating point</li> <li>1024KiB flash ROM and 192KiB RAM</li> <li>Micro USB connector for power and serial communication</li> <li>Micro SD card slot, supporting standard and high capacity SD cards</li> <li>3-axis accelerometer (MMA7660)</li> <li>Real time clock with optional battery backup</li> <li>24 GPIO on left and right edges and 5 GPIO on bottom row, plus LED and switch GPIO available on bottom row</li> <li>3x 12-bit analog to digital converters, available on 16 pins, 4 with analog ground shielding</li> <li>2x 12-bit digital to analog (DAC) converters, available on pins X5 and X6</li> <li>4 LEDs (red, green, yellow and blue)</li> <li>1 reset and 1 user switch</li> <li>On-board 3.3V LDO voltage regulator, capable of supplying up to 250mA, input voltage range 3.6V to 16V</li> <li>DFU bootloader in ROM for easy upgrading of firmware</li> </ol>"},{"location":"electronics/Development_Boards/Pyboard/#blink-sketch","title":"Blink Sketch","text":"<p>Similar to the blink sketch with Arduino, we can make a simple blink sketch with Pyboard using MicroPython.</p>"},{"location":"electronics/Development_Boards/Pyboard/#code","title":"Code","text":"<p>You can copy the code from here:</p> <pre><code>import pyb\nled = pyb.LED(4)\nwhile True:\n  led.on()\n  pyb.delay(1000)\n  led.off()\n  pyb.delay(1000)\n</code></pre>"},{"location":"electronics/Development_Boards/Pyboard/#how-to-code","title":"How to Code","text":"<ol> <li> <p>First connect the Pyboard to your computer using a USB. It will open up as a USB flash device with a boot python file and main python file.</p> <p>There are multiple ways to code a MicroPython program and run it on Pyboard. </p> </li> <li> <p>One beginner friendly way is to use a serial communication program like putty, which opens the interactive REPL prompt and now you can execute commands directly. Follow this tutorial to setup putty.</p> <p>NOTE: you have to press delete after the indented at the end of the while loop to end the indented block and then only will the loop start running. To exit out of the while loop, use ctrl+c.</p> </li> <li> <p>Another way is to run scripts from the built-in file system. Write to the main python file script using any text editor, save and close it. Make sure you eject the Pyboard USB drive and then only press the reset button on the PyBoard. You can use putty as a serial monitor.</p> </li> </ol>"},{"location":"electronics/Development_Boards/Pyboard/#references","title":"References","text":"<ol> <li>For documentation and quick reference, check out the official MicroPython website.</li> <li>For a quick introduction to MicroPython and Pyboard, check out this video.</li> <li>For a comparison with the Arduino, check out this video.</li> <li>To discuss all things related to MicroPython with an online community check out the MicroPython Forum.</li> </ol>"},{"location":"electronics/Development_Boards/STM32/","title":"Blue Pill (STM32F103C8T6)","text":""},{"location":"electronics/Development_Boards/STM32/#introduction","title":"Introduction","text":"<p>The STM32F103C8T6 (also known as \u2018STM32\u2019 or \u2018Blue Pill\u201d) is a cheap development board based on the ARM Cortex M3 microprocessor. This video by Great Scott can prove to be an introductory video to understand what it exactly is and how it can be used.</p> <p></p>"},{"location":"electronics/Development_Boards/STM32/#naming-convention-of-stm-microcontrollers","title":"Naming Convention of STM microcontrollers","text":"Parameter Meaning STM name of the manufacturer (STMicroelectronics) 32 32 bit ARM architecture F Foundation 1 Core (ARM Cortex M3) 03 Line (describes peripherals and speed)  C 48 pins  8 64 KB flash memory T LQFP package (Low Profile Quad Flat Pack)  6 Operating Temperature Range (-40 \u00b0C to 85 \u00b0C)"},{"location":"electronics/Development_Boards/STM32/#technical-specifications-of-stm32","title":"Technical Specifications of STM32","text":"Parameter Meaning Architecture 32 bit ARM Cortex M3  Operating Voltage 2.7V to 3.6V  CPU Frequency 72 MHz  Number of GPIO pins 37  Number of PWM pins 12  Analog Input Pins 10 (12 bit resolution)  I2C Peripherals 2  SPI Peripherals 2  CAN 2.0 Peripheral 1 Timers 3(16-bit), 1 Flash Memory 64KB RAM 20kB <p>For more insights about the technical specifcations refer to the official datsheet and reference manual by STMicroelectronics.</p>"},{"location":"electronics/Development_Boards/STM32/#pinout","title":"Pinout","text":""},{"location":"electronics/Development_Boards/STM32/#programming-stm32","title":"Programming STM32","text":""},{"location":"electronics/Development_Boards/STM32/#1-using-stm32duino-bootloader-arduino-ide","title":"1) Using STM32duino bootloader (Arduino IDE)","text":"<p>You can program your STM32 development board using Arduino IDE, too. You will require FTDI (USB to UART converter) for this process. This tutorial explains the complete process.</p>"},{"location":"electronics/Development_Boards/STM32/#2-using-keil-uvision-and-stm32cubemx","title":"2) Using Keil UVision and STM32CubeMX","text":"<p>This is one step further than the last mentioned process and is more professional in terms of usage. You will require the softwares ARM\u2019s Keil Uvision and STM32CubeMX for this method of programming BluePill. You will also need the STLink/V2 which is a debugger cum programmer hardware provided by STMicroelectronics. These softwares provide a more sophisticated and professional programming environment for programming embedded systems. You may refer to this guide to know this method in detail.</p>"},{"location":"electronics/Development_Boards/STM32vsArduinoUNO/","title":"Comparison between STM32F103C8T6 and Arduino UNO","text":"Parameter STM32F103C8T6 (Blue Pill) Arduino UNO Processor STM32F103C8T6 ATMega328P Operating Voltage 3.3V 5V CPU Speed 72 MHz 16 MHz Analog pins 10 8 Digital I/O or PWM 37 14 EEPROM/SRAM (KB) NA/20 1/2 Flash Memory 64/128 KB 32 KB USB Conector Micro Type B UART 3 1 SPI 2 1 I\u00b2C 2 1"},{"location":"electronics/Modules/wifi_module/","title":"Wi-Fi module","text":"<p>Wifi modules or wifi microcontrollers are used to send and recieve data over Wi-Fi. They can also accept commands over the Wi-Fi. Wi-Fi modules are used for communications bewtween devices. They are most commonly used in the field of Internet of Thnigs.</p>"},{"location":"electronics/Modules/wifi_module/#esp8266","title":"ESP8266","text":"<p>ESP8266 is the most widely used Wi-Fi module. It is a low-cost microchip with a full TCP/IP stack and microcontroller capability, produced by Espressif Systems. This small module allows microcontrollers to connect to a Wi-Fi network and make simple TCP/IP connections. </p> <p>ESP8226 comes with the capabilites of:- 1. 2.4 Ghz Wi-Fi 2. General-purpose input/output (16 GPIO) 3. Inter-Integrated Circuit (I\u00b2C) serial communication protocol 4. Analog-to-digital conversion (10-bit ADC)</p> <p>It runs at operating voltage of 3V and can handle maximum voltage of around 3.6V. It can be easily interfaced with microcontrollers board via Serial Port. There are numerous breakout boards available based on ESP8266 Wifi Module like ESP8266 NodeMCU V3. Because of its compact size, its most importantly used in autonomous project.</p>"},{"location":"electronics/Modules/wifi_module/#esp8266-pinout","title":"ESP8266 pinout","text":"Pin Number Pin Name Working 1 RX Serial Receiver Pin 2 VCC Power Pin (+3.3 V; can handle up to 3.6 V 3 GPIO 0 General-Purpose I/O No. 0 4 RST Reset 5 CH_PD Chip power-down 6 GPIO 2 General-purpose I/O No. 2 7 TX Serial Transmitter Pin 8 GND Ground"},{"location":"electronics/Modules/wifi_module/#scanning-and-dispalying-available-wifi-networks-using-esp8266","title":"Scanning and dispalying available WiFi networks using ESP8266","text":"<p>ESP8266 comes with a built in micro-controller. It has a Arduino support and can be programmed easily. </p>"},{"location":"electronics/Modules/wifi_module/#arduino-support-for-esp8266","title":"Arduino support for ESP8266","text":"<ol> <li> <p>Download Arduino IDE from Arduino.cc(1.6.4 or greater)</p> <p>https://www.arduino.cc/en/Main/Software</p> </li> <li> <p>Install the ESP8266 Board Package</p> <ul> <li>Select Preferences under File </li> <li>Enter http://arduino.esp8266.com/stable/package_esp8266com_index.json into Additional Boards Manager URL\u2019s field under preferences. </li> <li>Select the Board Manager under the Tools. </li> <li>Use the Board Manager to install the ESP8266 package. </li> <li>Restart the Arduino IDE and Select the Generic ESP8266 Module board </li> </ul> </li> </ol>"},{"location":"electronics/Modules/wifi_module/#connection","title":"Connection","text":"<p>A USB to serial converter is nedded to program ESP8266. The above image shows connections made from Explore USB to Serial and Explore Wifi boards.</p>"},{"location":"electronics/Modules/wifi_module/#code","title":"Code","text":"<pre><code>#include \"ESP8266WiFi.h\"\n\nvoid setup() {\nSerial.begin(115200);\n\n// Set WiFi to station mode and disconnect from an AP if it was previously connected\nWiFi.mode(WIFI_STA);\nWiFi.disconnect();\ndelay(100);\n\nSerial.println(\"Setup done\");\n}\n\nvoid loop() {\nSerial.println(\"scan start\");\n\n// WiFi.scanNetworks will return the number of networks found\nint n = WiFi.scanNetworks();\nSerial.println(\"scan done\");\nif (n == 0)\nSerial.println(\"no networks found\");\nelse\n{\nSerial.print(n);\nSerial.println(\" networks found\");\nfor (int i = 0; i &lt; n; ++i)\n{\n// Print SSID and RSSI for each network found\nSerial.print(i + 1);\nSerial.print(\": \");\nSerial.print(WiFi.SSID(i));\nSerial.print(\" (\");\nSerial.print(WiFi.RSSI(i));\nSerial.print(\")\");\nSerial.println((WiFi.encryptionType(i) == ENC_TYPE_NONE)?\" \":\"*\");\ndelay(10);\n}\n}\nSerial.println(\"\");\n\n// Wait a bit before scanning again\ndelay(5000);\n}\n</code></pre>"},{"location":"electronics/Modules/wifi_module/#references","title":"References","text":"<ol> <li>Documentation of ESP8266.h library.</li> <li>Technical Reference Manual by Espressif Systems.</li> <li>ESP8266 Community Forum</li> <li>ESP8266 for IoT guide by Nabto.</li> </ol>"},{"location":"electronics/Motors/ServoMotor/","title":"Servo Motors","text":"<p>Servo motors are simply just electric motors which give the users precise control over the angle of rotation, speed and torque of the motor. The shaft of a servo motor can be made to rotate by a certain angle and then it waits till the next signal is given to it. Moreover, the speed and torque, and in certain applications, even the sense of rotation of the motor can be adjusted by changing the command signal given to the motor. Whereas on the other hand, this is not possible in a simple electric motor, as it runs at a constant speed in the same direction as long as it is connected to a constant power supply. Apart from increased control, servo motors also provide high precision owing to its working principle - the servomechanism.</p>"},{"location":"electronics/Motors/ServoMotor/#what-is-servomechanism","title":"What is Servomechanism ?","text":"<p>Servomechanism is a closed loop control system which aims at achieving a fixed value of the output based on the given command, without using a variable input signal. It works by calculating the difference between the reference input signal or the command signal and the output signal received from a sensor. The feedback signal thus obtained, acts as the input signal for the device to be controlled. Hence, with the help of this feedback mechanism, we can make the output equal the reference input without having to alter the reference input manually at regular intervals. Once the output signal becomes equal to the command signal, the feedback signal goes to zero and hence the process stops till a new command signal is given.</p>"},{"location":"electronics/Motors/ServoMotor/#working-of-a-servo-motor","title":"Working of a Servo motor","text":"<p>A servo motor construction consists of a simple electric motor, some gears, a potentiometer/encoder/resolver, an error detector amplifier, and a control circuit.  Potentiometers, encoders and resolvers all perform the same function by acting as sensors that measure the rotary position of the motor shaft. There are however certain differences in the way they function. If interested, you can take a look at these resources which give a detailed comparison between </p> <ul> <li>Potentiometer and Encoder</li> <li>Encoder and Resolver</li> </ul> <p>Let us consider the simple case of a potentiometer used in the servo motor to clearly understand its working.  The potentiometer gives the output reference signal by sensing the position of the shaft, hence its knob is positioned such that it does not produce any signal in the initial condition. Now, the command signal, i.e. the input reference signal,  is introduced. This command signal represents how much we want the motor shaft to rotate. Next, the input reference signal and the output reference signal are fed into the error detector amplifier, where their difference is amplified and then generated as the output. This output from the amplifier acts as the input signal for the servo motor, which now starts rotating. The knob of the potentiometer is linked to the motor shaft with the help of a gear arrangement. Thus, as the shaft rotates, the knob of the potentiometer also rotates in a way such that the difference between the input and output reference signals decreases until it becomes zero. When the difference becomes zero, the output of the amplifier also goes to zero and no input signal will be given to the motor, due to which it stops rotating. Now it will remain in this condition until a new command signal is given, so that it generates a difference with the output from the potentiometer, and the process is repeated again.</p>"},{"location":"electronics/Motors/ServoMotor/#applications-of-servo-motors","title":"Applications of Servo motors","text":"<p>Servo motors have a wide variety of applications ranging from RC toys to industrial machines. They are built in cameras to adjust the focus of the lens. Servo motors are even found in DVD players, where they are used to open/close the disk tray. Due to their high precision and ability to rotate by a desired angle, they are also used in cutting machines such as the milling machine. Servo motors also find numerous applications in the field of robotics, where they are actively being used for making mobile robots as well as to make movable joints in robotic arms which require highly accurate movements.  Depending upon their application, there are different types of servo motors. You can check out these websites ( 1 and 2 ) to know more on this.</p>"},{"location":"electronics/Sensors/lidar/","title":"Lidar","text":"<p>Lidar is a method for calculating distances between objects with the help of a laser and measuring the amount of time taken for the reflected light to return back.</p>"},{"location":"electronics/Sensors/lidar/#lidar-sensor","title":"Lidar Sensor","text":"<p>A Lidar sensor emits pulsed light waves into the surrounding environment. These pulses bounce off of    obstacles and the surrounding environment and then return to the sensor. The sensor then, keeps a track of time it took for the light to bounce off and thus calculating the distance between obstacles. Repeating this process constantly creates a real-time map of the environment.</p> <p></p> <p>As an example of how a lidar sensor calculates the distance between the sensor and an obstacle,</p> <p>Let\u2019s define the following variables, 1) Speed of light, \\(c = 3 \u00d7 10^8 m/s\\) 2) time taken for light to travel from the lidar sensor, hitting the obstacle and returning back to the sensor, \\(t\\) 3) Distance between the obstacle and the sensor, \\(d\\)</p> <p>Say that the time taken, \\(t = 5 \u00d7 10^{-8} sec\\) (Observe the order of magnitude \\(t\\))</p> <p>So, to calculate the distance \\(d\\), we use the Newton\u2019s second law of motion</p> \\[ S = u \\cdot t + \\frac{1}{2} \\cdot a \\cdot t^2 \\] <p>Since, speed of light constant, replacing, \\(a = 0\\), \\(u = c\\), and, \\(S = d\\)  we get,</p> \\[ d = c \\cdot t \\] \\[ d = 3 \u00d7 10^8 \u00d7 5 * 10^{-8} \\] \\[ d = 15m \\] <p>Therfore, the distance between the sensor and the obstacle is calculated to be 15 meters. This is the basic calculation that goes into calculating the distances.</p>"},{"location":"electronics/Sensors/lidar/#types-of-lidar-systems","title":"Types of Lidar Systems","text":"<p>1) Airborne Lidar - This is installed on aerial drones or vehicles like helicopters. It emits light towards the ground surface giving a fairly detailed and quick map of the terrain above which the vehicle or drone is flying. It is also used for topographic survey.</p> <p></p> <p>2) Terrestrial Lidar - This is generally installed on vehicles moving on the earth\u2019s surface. These give a detailed map, and can be used to make a robot or a vehicle navigate through it\u2019s evironment. It is also used for observing highways, roads and infrastructure.</p> <p></p>"},{"location":"electronics/Sensors/lidar/#components-of-a-basic-lidar-sensor","title":"Components of a basic Lidar Sensor","text":"<p>A lidar sensor generally consists of 4 main components:  1) Light source - Generally a laser (or anything that emits light in pulses) 2) Optical components - There are multiple optical components for example, the light through the sensor, falls on a rotating/oscillating mirror so as to change the direction of light to cover a 360 view. An optical lens helps to focus light on the photodetector. 3) photodector - The light is recieved by this photodetector and the signal is processed electronically like frequency of light (for speed measurements) and the time taken for the light to bounce. 4) GPS - These sensors need a GPS system to determine the exact position and orientation of the sensor in 3D space.</p> <p>For a more indepth explaination of a Lidar sensor and the different factors that go into designing one, for example, the wavelength of light to use, the pulsing rate of the light or pulse repetition rate and more factors can be found here.</p>"},{"location":"electronics/Sensors/lidar/#lidar-usage","title":"Lidar usage","text":"<p>To implement Lidar into your ros program, these are the following steps you must follow: * Connect your Lidar sensor to a power supply, and connect a data transmitter to the Lidar sensor and the computer. * You need to give permissions to the on data input port of the computer. To check the permissions, type</p> <pre><code>ls -l /dev/tty\n</code></pre> <ul> <li>If your permissions are set properly, you should get an output like shown below. Just focus on the starting part, <code>crw-rw-rw</code>. If instead, it is something of the form <code>crw-rw--</code>, then your permissions are not set properly.</li> </ul> <pre><code>crw-rw-rw- 1 root dialout 5, 0 Sep  6 23:50 /dev/ttyACM0\n</code></pre> <ul> <li>To set permissions, (replace <code>ACM0</code> with whatever your ports are)</li> </ul> <pre><code>sudo chmod a+rw /dev/ttyACM0\n</code></pre> <ul> <li> <p>Next, you need to download the package of your Lidar manufacturer. Following are the common packages and their github links. You need to clone these github repositories in the src directory of your catkin workspace.</p> <p>1) Slamtec 2) YDLiDAR 3) Hokuyo 4) ROS SICK 5) ROS2 SICK 6) RoboSense * After you have cloned the ros packages, go into your workspace directory,</p> </li> </ul> <pre><code>catkin_make\nsource devel/setup.bash\n</code></pre> <ul> <li> <p>Now just run the launch file according to your Lidar manufacturer package. For the above 6 manufacturers, run the following launch files. (If you are getting package not found error, please give appropriate permissions to the launch files using chmod).</p> <p>1) Slamtec     <code>bash     roslaunch rplidar_ros rplidar.launch</code> 2) YDLiDAR     <code>bash     roslaunch ydlidar lidar_view.launch</code> 3) Hokuyo     <code>bash     roslaunch urg_node urg_lidar.launch</code> 4) ROS SICK - Read the README file in the github repo for which launch file you need for your specific model.</p> <p>5) ROS2 SICK - Read the README file in the github repo for which launch file you need for your specific model.</p> <p>6) RoboSense     <code>bash     roslaunch rslidar_sdk start.launch</code></p> </li> </ul> <p>For a much more detailed guide, use this link. This shows a fairly detailed explaination on how to setup your lidar to interact with ROS and display the results in rviz. It also has some examples of implementation and different repositories that would help you to code.</p> <p>You can also check out this link which provides a simple explaination for setting up a YDLiDAR X4 Sensor.</p>"},{"location":"electronics/Sensors/lidar/#applications-of-lidar","title":"Applications of Lidar","text":"<p>1) Surveying land - Lidar sensors can generate a cost effective solution for generating a 3D digital terrain model of remote or rough areas which are difficult to assess otherwise. (Nasa used Lidar techonology to explore mars). For more information on Airborne Lidar and Topographic survey, check out this research paper. 2) Power line inspection - Power lines span very long distances and thus make the inspection of power lines very difficult. Lidar sensors can make the inspection easier, by identifying faults before they can cause any real damage. 3) Farming and Forest research - These can be deployed to large farms to help determine how to use resources in an efficient manner and boost productivity. They can also be used to research on the impact that humans have caused on natural life in forests, as Lidar sensors can penetrate tree cover. 4) Climate and weather change - Climate scientists use Lidar to study and track changes in the atmosphere. Lidar can also be used to warn people if there is a Tsunami incoming. 5) Robotics - Lidar is used to equip robots with Mapping and navigational capabilities. For example, self driving cars.</p>"},{"location":"electronics/Sensors/lidar/#companies-working-on-lidar-technologies","title":"Companies working on Lidar technologies","text":"<p>1) tuSimple - works on self driving cars which is almost commercial ready. 2) AEye - Develops advanced vision hardware, software and algorithms for autonomous vehicles. 3) SiLC Technologies - Is a leading provider of highly integrated FMCW (Frequency Modulated Continuous Wave) Lidar solutions, which include their FMCW integration chip.</p>"},{"location":"electronics/Sensors/lidar/#references-","title":"References -","text":"<ul> <li> <p>George, N., 2021. 11 Interesting LiDAR Applications. [online] Blog.cloudfactory.com. Available at: https://blog.cloudfactory.com/interesting-lidar-applications [Accessed 7 September 2021].</p> </li> <li> <p>Geospatial World. 2021. What is LiDAR technology and how does it work?. [online] Available at: https://www.geospatialworld.net/blogs/what-is-lidar-technology-and-how-does-it-work/ [Accessed 7 September 2021].</p> </li> <li> <p>Microdrones.com. 2021. 5 Compelling Applications for LiDAR Technology. [online] Available at: https://www.microdrones.com/en/content/5-compelling-applications-for-lidar-technology/ [Accessed 7 September 2021].</p> </li> <li> <p>Sentech. 2021. The revealing science behind Lidar technology. [online] Available at: https://www.sentech.nl/en/sensor-technology/revealing-science-behind-lidar-technology/ [Accessed 7 September 2021].</p> </li> <li> <p>Velodyne Lidar. 2021. What is Lidar? Learn How Lidar Works | Velodyne Lidar. [online] Available at: https://velodynelidar.com/what-is-lidar/ [Accessed 7 September 2021].</p> </li> </ul>"},{"location":"mechanical/Forward%20and%20Inverse%20Kinematics/","title":"Forward Kinematics","text":"<p>The forward kinematics problem for a serial-chain manipulator is to find the position and orientation of the end-effector relative to the base given the positions of all of the joints and the values of all of the geometric link parameters. Often, a frame fixed in the end-effector is referred to as the tool frame, and while fixed in the final link N, it in general has a constant offset in both position and orientation from frame N. Likewise, a station frame is often located in the base to establish the location of the task to be performed. This frame generally has a constant offset in its pose relative to frame 0, which is also fixed in the base. In practice, the forward kinematics problem is solved by calculating the transformation between a coordinate frame fixed in the end-effector and another coordinate frame fixed in the base, i.e., between the tool and station frames. This is straightforward for a serial chain since the transformation describing the position of the end-effector relative to the base is obtained by simply concatenating transformations between frames fixed in adjacent links of the chain.</p> <p></p>"},{"location":"mechanical/Forward%20and%20Inverse%20Kinematics/#inverse-kinematics","title":"Inverse Kinematics","text":"<p>The inverse kinematics problem for a serial-chain manipulator is to find the values of the joint positions given the position and orientation of the end-effector relative to the base and the values of all of the geometric link parameters. Once again, this is a simplified statement applying only to serial chains. A more general statement is: given the relative positions and orientations of two members of a mechanism, find the values of all of the joint positions. This amounts to finding all of the joint positions given the homogeneous transformation between the two members of interest. When solving the inverse problem, we often have to choose one solution from a number of valid solutions. There are also degenerate cases with an infinite number of solutions Some solutions of the inverse mapping may not be physically realizable. This is due to manipulators having physical joint limits that prevent the mechanism from achieving certain joint configurations that may be solutions to the inverse kinematics problem (e.g. a joint may not have a full 360 degree motion)</p> <p> <p></p> <p>To get a more detailed idea of solving inverse and forward kinematics problems for robotic system do checkout this 3 part video series from milfordrobotics</p> <p>Part-1, Part-2, Part-3</p>"},{"location":"mechanical/Gears/","title":"Gears","text":""},{"location":"mechanical/Gears/#what-are-gears","title":"What are Gears?","text":"<ul> <li>Gears are defined as toothed element which are used for transmitting rotary motion from one shaft to another.</li> <li>Gears are most often used in transmissions to convert an electric motor\u2019s high speed and low torque to a shaft\u2019s requirements for low speed high torque.</li> <li>Gears essentially allow positive engagement between Teeth, so high forces can be transmitted while still undergoing essentially rolling contact.</li> <li>Gears do not depend on friction as belt drives and do best when friction is minimized.</li> <li>The motion and power transmitted by gears is kinematically equivalent to that transmitted by friction wheels or discs.</li> </ul> <p> <p>(Transmission of Power)</p> <ul> <li>In order to avoid the slipping, a number of projections (called teeth) as shown in Fig. (b), are provided on the periphery of the wheel A, which will fit into the corresponding recesses on the\u00a0 periphery of the wheel B. A friction wheel with the teeth cut on it is known as toothed wheel or gear. The usual connection to show the toothed wheels is by their pitch circles</li> </ul> <p></p>"},{"location":"mechanical/Gears/#advantages-and-disadvantages","title":"Advantages and Disadvantages","text":""},{"location":"mechanical/Gears/#advantages","title":"Advantages","text":"<ol> <li>It transmits exact velocity ratio.</li> <li>It may be used to transmit large power.</li> <li>It has high efficiency.</li> <li>It has reliable service.</li> <li>It has compact layout.</li> </ol>"},{"location":"mechanical/Gears/#disadvantages","title":"Disadvantages","text":"<ol> <li>The manufacture of gears require special tools and equipment.</li> <li>The error in cutting teeth may cause vibrations and noise during operation.</li> </ol>"},{"location":"mechanical/Gears/#types-of-gears","title":"Types of Gears","text":"<ul> <li> <p>According to the position of axes of the shaft</p> <ul> <li>Parallel: Spur gear, Helical gear, Rack and Pinion</li> <li>Intersecting: Bevel Gear</li> <li>Non Intersecting and Non Parallel: Worm and Worm Gears</li> </ul> </li> <li> <p>According to the periphery velocity</p> <ul> <li>Low Velocity</li> <li>Medium Velocity</li> <li>High Velocity</li> </ul> </li> <li> <p>According to the type of gearing</p> <ul> <li>External Gearing</li> <li>Internal Gearing</li> <li>Rack and Pinion</li> </ul> </li> <li> <p>According to the position of teeth on surface</p> <ul> <li>Straight</li> <li>Inclined</li> <li>Curved</li> </ul> </li> </ul>"},{"location":"mechanical/Gears/#spur-gear","title":"Spur Gear","text":"<p>Spur gears are a type of cylindrical gear, with shafts that are parallel and coplanar, and teeth that are straight and oriented parallel to the shafts. They\u2019re arguably the simplest and most common type of gear \u2013 easy to manufacture and suitable for a wide range of applications.</p> <p></p> <p>The teeth of a spur gear have an involute profile and mesh one tooth at a time. The involute form means that spur gears only produce radial forces (no axial forces), but the method of tooth meshing causes high stress on the gear teeth and high noise production. Because of this, spur gears are typically used for lower speed applications, although they can be used at almost any speed.</p> <p></p> <p>Spur gears are generally seen as best for applications that require speed reduction and torque multiplication, such as ball mills and crushing equipment. Examples of high-speed applications that use spur gears \u2013 despite their high noise levels \u2013 include consumer appliances such as washing machines and blenders. And while noise limits the use of spur gears in passenger automobiles, they are often used in aircraft engines, trains, and even bicycles.</p>"},{"location":"mechanical/Gears/#helical-gear","title":"Helical Gear","text":"<p>The teeth of a helical gear are set at an angle (relative to axis of the gear) and take the shape of a helix. This allows the teeth to mesh gradually, starting as point contact and developing into line contact as engagement progresses.</p> <p>One of the most noticeable benefits of helical gears over spur gears is less noise, especially at medium- to high-speeds. Also, with helical gears, multiple teeth are always in mesh, which means less load on each individual tooth. This results in a smoother transition of forces from one tooth to the next, so that vibrations, shock loads, and wear are reduced. One interesting thing about helical gears is that if the angles of the gear teeth are correct, they can be mounted on perpendicular shafts, adjusting the rotation angle by 90 degrees.</p> <p></p> <p>Helical gears are often the default choice in applications that are suitable for spur gears but have non-parallel shafts. They are also used in applications that require high speeds or high loading. And regardless of the load or speed, they generally provide smoother, quieter operation than spur gears.</p>"},{"location":"mechanical/Gears/#bevel-gear","title":"Bevel Gear","text":"<p>Bevel gears\u00a0are\u00a0gears\u00a0where the axes of the two\u00a0shafts\u00a0intersect and the\u00a0tooth-bearing faces of the gears themselves are conically shaped. Bevel gears are most often mounted on shafts that are 90 degrees apart, but can be designed to work at other angles as well. The pitch surface of bevel gears is a\u00a0cone.</p> <p></p> <p>There are several\u00a0types of bevel gears\u00a0based on the shape of their teeth.</p> <ul> <li> <p>Straight</p> <ul> <li>They have conical pitch surface and teeth are straight and tapering towards apex.</li> <li>They are useful to verify the transmission of the motion that is generated between axes that intersect within one same plane, almost always at a\u00a090-degree\u00a0angle.</li> <li>Straight bevel gears have many uses in\u00a0watches, dentist drills, hand drills and vending machines.</li> </ul> </li> <li> <p>Spiral</p> <ul> <li>They have curved teeth at an angle allowing tooth contact to be gradual and smooth and operate at very steep planes.</li> <li>Spiral bevel gears provide a\u00a0high level of control over the way in which teeth mesh, and their design allows for certain mounting deflections without excessively increasing the load on either end of the teeth.</li> <li>They can be used at high speeds, and are usually employed in\u00a0motorcycle and bicycle gears.</li> </ul> </li> <li> <p>Hypoid</p> <ul> <li>These are similar to spiral bevel, but the pitch surfaces are\u00a0hyberbolic\u00a0and not conical. The pinion can be offset above or below the gear center, thus allowing larger pinion diameter, longer life, and smoother mesh.</li> <li>In addition to being used in industrial machinery, they are commonly used in the automotive industry, where it is used in\u00a0rear-wheel drive vehicles\u00a0to connect the driveshaft with the wheels.</li> </ul> </li> </ul>"},{"location":"mechanical/Gears/#worm-gears","title":"Worm Gears","text":"<p>Worm gears are constructed of a worm and a gear (sometimes referred to as a worm wheel), with non-parallel, non-intersecting shafts oriented 90 degrees to each other. The worm is analogous to a screw with a V-type thread, and the gear is analogous to a spur gear. The worm is typically the driving component, with the worm\u2019s thread advancing the teeth of the gear.</p> <p></p> <p>The primary benefit of worm gears is their ability to provide high reduction ratios (like 20:1 and even up to 300:1 or greater) and correspondingly high torque multiplication. They can also be used as speed reducers in low- to medium-speed applications. And, because their reduction ratio is based on the number of gear teeth alone, they are more compact than other types of gears. Worm gears are used widely in material handling and transportation machinery, machine tools, automobiles etc.</p>"},{"location":"mechanical/Gears/#herringbone-gear","title":"Herringbone Gear","text":"<p>The herringbone gear consists of two sets of gear teeth on the same gear, one right hand and one left hand. Having both hands of gear teeth, causes the thrust of one set to cancel out the thrust of the other. It is used for transmitting power between parallel shafts. It was developed to overcome the disadvantage of the high-end thrust that is present with single-helical gears. Also another advantage of this gear type is quiet, smooth operation at higher speeds. They are mostly used on heavy machinery.</p> <p></p>"},{"location":"mechanical/Gears/#rack-and-pinion","title":"Rack and Pinion","text":"<p>A rack and pinion drive system consists of a rack (or a \u201clinear gear\u201d) and a pinion (or \u201ccircular gear\u201d), which operate to convert rotational motion into linear motion. A rack and pinion drive can use both straight and helical gears. These systems provide high-speed travel over extremely long lengths and are frequently used in large gantry systems for material handling, machining, welding and assembly, especially in the automotive, machine tool, and packaging industries.</p> <p></p>"},{"location":"mechanical/Introduction%20to%20Dynamics/","title":"Introduction to Dynamics","text":"<p>For many applications with fixed-based robots we need to find a multi-body dynamics formulated as:</p> \\[ M(q)\\ddot{q} + b(q,\\dot{q}) + g(q) = \\tau \\: + J_{c}(q)^{T}F_{c} \\] <p>consisting of the following components:</p> <p>\\(M(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}\\) \\(^{n_{q}Xn_{q}}\\)  Generalized Mass matrix(orthogonal)</p> <p>\\(q, \\dot{q}, \\ddot{q}\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\)        Generalized position, velocity and acceleration vectors</p> <p>\\(b(q, \\dot{q})\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\)        Coriolis and centrifugal terms.</p> <p>\\(g(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\)        Gravitational terms.</p> <p>\\(\\tau\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\)        External generalized forces.</p> <p>\\(F_{c}\\) \\(\\epsilon\\)   $\\(\\mathbf{R}^{n_{q}}\\)         External Cartesian forces (e.g. from contacts)</p> <p>\\(J_{c}(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}Xn_{q}}\\)    Geometric Jacobian corresponding to the external forces.</p> <p>Different methods exist to compute the so-called Equations of Motion (EoM) of a given system, i.e., a closed-form mathematical model of the system dynamics. The two most common methods used in robotics are Newton-Euler method which essentially applies the principles of conservation of linear and angular momentum for all links of a robot and Lagrange Method which utilizes scalar energy-based functions over the the space of generalized coordinates which adhere to certain minimization principles, thus resulting in trajectories which automatically satisfy the kinematic constraints of the system.</p> <p>to understand better how problems related to dynamics in robotics are tackled do give a watch to this lecture on robot dynamics by IIT KGP Prof. Dilip Kumar Pratihar  </p>"},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-method","title":"Newton-Euler Method","text":""},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-for-single-bodies","title":"Newton-Euler for Single Bodies","text":"<p>a very well known formulation formed by Newton and Euler using law of angular and linear momentum is :</p> <p>\u200b                                                                       \\(\\dot{\\mathsf{p}} _{S}\\) = \\(F_{ext,S}\\)</p> <p>\u200b                                                                       \\(\\dot{\\mathbf{N}}_{S}\\) = \\(T_{ext}\\)</p> <p>where \\(F_{ext,S}\\) are the resultant external forces that act through the COG and  \\(T_{ext}\\) are the resultant external torques. External forces which do not act through the COG need to be shifted to an equivalent force/moment pair of which the force acts through the COG.</p>"},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-for-multi-body-systems","title":"Newton-Euler for Multi-Body Systems","text":"<p>When dealing with multi-body systems, a valid approach is to separate all bodies at the joints as depicted in and to consider every body as a single unit. Thereby, the constraint forces F\\(_{i}\\) at the joints must be introduced as external forces acting on each of the bodies when cut free. For all these bodies, we must then apply conservation of linear and angular momentum in all DoFs, subject to external forces (which now include the joint forces F\\(_{i}\\) , too). For a general 3D case and a fixed base, this results in a 6\\(n_{j}\\) -dimensional systems of equations. Additionally, there are 5 \\(n_{j}\\) motion constraint due to the ideal joints. They ensure that the two connected bodies only move along the direction of the joint but don\u2019t move in all other directions that are blocked by the joint.</p> <p></p>"},{"location":"mechanical/Introduction%20to%20Dynamics/#lagrange-method","title":"Lagrange Method","text":"<p>This method is centered around three fundamental concepts:</p> <ol> <li> <p>The definition of generalized coordinates$ q$ and generalized velocities \\(\\dot{q}\\) , which may or may not encode the information regarding the constraints applicable to the system.</p> </li> <li> <p>. A scalar function called the Lagrangian function \\(\\mathcal{L}\\). For mechanical systems, it is exactly the difference between the total kinetic energy \\(\\mathcal{T}\\) and the total potential energy \\(\\mathcal{U}\\), of the system at each instant:</p> </li> </ol> <p>\u200b                                                         \\(\\mathcal{L} = \\mathcal{T} - \\mathcal{U}\\)</p> <ol> <li>The so-called Euler-Lagrange equation, also known as the Euler-Lagrange of the second kind, which applies to the Lagrangian function \\(\\mathcal{L}\\) and to the total external generalized forces \\(\\tau\\) :</li> </ol> <p>\u200b                                            \\(\\frac{d}{dt} (\\frac{\\partial{\\mathcal{L}}}{\\partial{\\dot{q}}} )\\)  -  \\((\\frac{\\partial{L}}{\\partial{\\dot{q}}})\\)      =   \\(\\tau\\)</p> <p>In the most general case, the Lagrangian is a function of the generalized coordinates and velocities q and q\u02d9 , and it may also have an explicit dependence on time t, hence we redefine the aforementioned scalar energy functions as \\(\\mathcal{T} = \\mathcal{T}(t, q, \\dot{q})\\) and \\(\\mathcal{U} = \\mathcal{U}(t,q)\\), thus \\(\\mathcal{L} = \\mathcal{L}(t,q,\\dot{q})\\) .</p> <p>In the end, one of the most notable properties of this formulation is the capacity to eliminate all internal reaction forces of the system from the final EoM, in contrast to the Newton-Euler formulation where there they are explicitly accounted for.</p> <p>To get a more detailed insight on how to formulate Newton-Euler equation and Lagrange equation  for different robot system check out this lecture by IIT Delhi prof S.K SAHA</p> <p>some of the other resources you can checkout to know more about kinematics and dynamics involved in robotics are:</p> <ol> <li>A Mathematical Introduction to Robotic Manipulation by Richard Murray</li> <li>Robot dynamics and control by Mark Spong</li> <li>Springer Handbook on Robotics by Oussama Khatib</li> </ol>"},{"location":"mechanical/Joint%20Kinematics/","title":"Joint Kinematics","text":"<p>The links that compose the robotic mechanism are assumed to be perfectly rigid bodies having surfaces that are geometrically perfect in both position and shape. Accordingly, these rigid bodies are connected together at joints where their idealized surfaces are in ideal contact without any clearance between them. The respective geometries of these surfaces in contact determine the freedom of motion between the two links, or the joint kinematics.</p>"},{"location":"mechanical/Joint%20Kinematics/#revolute","title":"Revolute","text":"<p>The most general form of a revolute joint, often abbreviated as R and sometimes referred to colloquially as a hinge or pin joint, is a lower pair composed of two congruent surfaces of revolution. The surfaces are the same except one of them is an external surface, convex in any plane normal to the axis of revolution, and one is an internal surface, concave in any plane normal to the axis. The position of one body relative to the other may be expressed as the angle between two lines normal to the joint axis, one fixed in each body. Thus, the joint has one degree of freedom (DOF).</p>"},{"location":"mechanical/Joint%20Kinematics/#prismatic","title":"Prismatic","text":"<p>The most general form of a prismatic joint, often abbreviated as P and sometimes referred colloquially as a sliding joint, is a lower pair formed from two congruent general cylindrical surfaces. A prismatic joint permits only sliding of one of the members joined relative to the other along the direction of extrusion. The position of one body relative to the other is determined by the distance between two points on a line parallel to the direction of sliding, with one point fixed in each body. Thus, this joint also has one degree of freedom.</p>"},{"location":"mechanical/Joint%20Kinematics/#helical","title":"Helical","text":"<p>The most general form of a helical joint, often abbreviated as H and sometimes referred to colloquially as a screw joint, is a lower pair formed from two helicoidal surfaces formed by extruding any curve along a helical path. The simple example is a bolt and nut wherein the basic generating curve is a pair of straight lines.</p> <p>Other types of joints include Planar, Spherical, Cylindrical, etc.</p>"},{"location":"mechanical/Joint%20Kinematics/#6-dof-joint","title":"6-DOF Joint","text":"<p>The motion of two bodies not jointed together can be modeled as a six-degree-of-freedom joint that introduces no constraints. This is particularly useful for mobile robots, such as aircraft, that make at most intermittent contact with the ground, and thus, a body in free motion relative to the fixed frame is termed a floating base. Such a free motion joint model enables the position and orientation of a floating base in space to be expressed with six joint variables.</p>"},{"location":"mechanical/Joint%20Kinematics/#geometric-representation","title":"Geometric Representation","text":"<p>The geometry of a robotic mechanism is conveniently defined by attaching coordinate frames to each link. While these frames could be located arbitrarily, it is advantageous both for consistency and computational efficiency to adhere to a convention for locating the frames on the links. A commonly used convention for selecting frames of reference in robotic applications is the Denavit-Hartenberg, or D-H convention. In this convention, each homogeneous transformation \\(A_{i}\\) is represented as a product of four basic transformations</p> <p></p> <p>where the four quantities \\(\\theta_{i} , a_{i} , d_{i} , \\alpha_{i}\\) are parameters associated with link i and joint i. The four parameters \\(a_{i} ,\\alpha_{i} ,d_{i} , and \\: \\theta_{i}\\) in are generally given the names link length, link twist, link offset, and joint angle, respectively, three of the above four quantities are constant for a given link, while the fourth parameter, \\(\\theta i\\) for a revolute joint and \\(d_{i}\\) for a prismatic joint, is the joint variable.</p> <p>Check out this video to know more about how to use DH parameters for geometric representation or go here for know about DH notation in more detail.</p> <p></p>"},{"location":"mechanical/Sandbox_usage/","title":"Sandbox equipment usage","text":"<p>Sandbox Lab is heavily utilised by all the ERC projects. Therefore the knowledge and mastery of operation ensures the success of the project concerning hardware and time. Attached below is a doc which contains elaborate description of: 1) Fused deposition modeling (3D Printing) : Explanination of usage on Ultimaker Cura (slicing software for FDM 3D printing) </p> <p>Sandbox Equipment Operation</p>"},{"location":"mechanical/drive_mechanism/","title":"Drive Mechanism","text":"<p>Wheeled mobile robots may be classified in two major categories, omnidirectional and nonholonomic.</p> <p>Omnidirectional wheeled mobile robots typically employ either omniwheels or mecanum wheels. An omniwheel is a typical wheel augmented with rollers on its outer circumference. These rollers spin freely about axes in the plane of the wheel and tangential to the wheel\u2019s outer circumference, and they allow sideways sliding while the wheel drives forward or backward without slip in that direction. Mecanum wheels are similar except that the spin axes of the circumferential rollers are not in the plane of the wheel. The sideways sliding allowed by omniwheels and mecanum wheels ensures that there are no velocity constraints on the robot\u2019s chassis.</p> <p>Nonholomic wheeled robots are subject to a single Pfaffian velocity constraint i.e. they cannot move sideways or parallel to the axis of the axel. Example for a nonholomic wheeled robot is a car and despite this velocity constraint, a car can reach any \\((\\phi,x,y)\\) configuration in an obstacle-free plane. In other words, the velocity constraint cannot be integrated to an equivalent configuration constraint, and therefore it is a nonholonomic constraint.</p> <p>If we want to prescribe the robot\u2019s movements in the environment, we need to know how the robot variables relate to the primary variables we can control: the angular positions and velocities of the wheel shafts. Therefore, a kinematical model of the robot has to be developed.</p>"},{"location":"mechanical/drive_mechanism/#modeling-of-an-omnibase-robot","title":"Modeling of an Omnibase Robot","text":"<p>Generally Omni wheeled robots use either a three wheeled platform or a four wheeled platform. Each design has its own advantages and disadvantages. In a three wheel design, wheels are at \\(120^{\\circ}\\) from each other and they offers greater traction as any reactive force is distributed through only three points and the robot is well balanced even on uneven terrain.</p> <p></p> <p>The configuration of a robot is defined in the form \\(q = (x,y,\\theta)\\), \\(d\\) is the distance between wheels and the center of the robot \\(v_i\\) and \\(\\omega_i\\) are the linear and angular velocity of the \\(i^{th}\\) wheel respectively. \\(v, v_n\\) are the two components of the linear velocity of the robot and \\(\\omega\\) is the angular velocity. The well known kinematic model of an omnidirectional robot located a \\((x,y,\\theta)\\) can be written as \\(v_x(t) = dx(t)/dt , v_y(t) = dy(t)/dt\\) and \\(\\omega(t) = d\\theta(t)/dt\\). For a three wheeled robot</p> \\[ \\begin{bmatrix} v_0(t)\\\\ v_1(t)\\\\ v_2(t) \\end{bmatrix} = \\begin{bmatrix} -sin\\pi/3 &amp; cos\\pi/3 &amp; d\\\\ 0 &amp; -1 &amp; d\\\\ sin\\pi/3 &amp; cos\\pi/3 &amp; d \\end{bmatrix} \\begin{bmatrix} v(t)\\\\ v_n(t)\\\\ \\omega(t) \\end{bmatrix} \\] <p>Applying the inverse kinematics is possible to obtain the equations that determine the robot speeds related the wheels speed. Solving in order of \\(v\\), \\(v_n\\) and \\(\\omega\\), the following can be found</p> \\[ v(t) = (\\sqrt{3}/3)(v_2(t) - v_0(t))\\] \\[v_n(t)=(1/3)(v_2(t) +v_0(t))\u2212(2/3)v_1(t)\\] \\[\\omega(t)=(1/(3d))(v_0(t) +v_1(t) +v_2(t)) \\]"},{"location":"mechanical/drive_mechanism/#modeling-of-a-nonholomic-robot","title":"Modeling of a Nonholomic Robot","text":"<p>A nonholomic robot is modelled in differnet ways which will then dictate the drive mechanism that can be applied on the robot. Differnet drive mechanism and modelling for a nonholomic robot are:</p> <ul> <li>Unicycle model</li> <li>Differential Drive</li> <li>Ackermann Steering</li> </ul>"},{"location":"mechanical/drive_mechanism/#unicycle-model","title":"Unicycle Model","text":"<p>The simplest wheeled mobile robot is a single upright rolling wheel, or unicycle. The configuration of a robot with a wheel of radius \\(r\\) can be written in the form \\(q = (\\phi,x,y,\\theta)\\), where \\((x,y)\\) is the contact point, \\(\\phi\\) is the heading direction, and \\(\\theta\\) is the rolling angle of the wheel. The kinematic equations can be written as</p> <p></p> \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1\\\\ rcos\\phi &amp; 0\\\\ rsin\\phi &amp; 0\\\\ 1 &amp; 0 \\end{bmatrix}  \\begin{bmatrix} u_1\\\\ u_2 \\end{bmatrix} = G(q)u = g_1(q)u_1 + g_2(q)u_2 \\] <p>The control inputs are \\(u = (u_1,u_2)\\), with \\(u_1\\) the wheel\u2019s forward-backward driving speed and \\(u_2\\) the heading direction turning speed.</p> <p>Three things to notice about these models are: (1) there is no drift - zero controls mean zero velocity; (2) the vector fields \\(g_i(q)\\) are generally functions of the configuration \\(q\\); and (3) \\(\\dot{q}\\) is linear in the controls.</p>"},{"location":"mechanical/drive_mechanism/#differnetial-drive","title":"Differnetial Drive","text":"<p>A differential drive is the most basic drive, which consists of two sets of wheels that can be driven independently. This is the most commonly used form of locomotion system used in robots as it\u2019s the simplest and easiest to implement.</p> <p>A differential drive robot consists of two independently driven wheels of radius \\(r\\) that rotate about the same axis, as well as one or more caster wheels, ball casters, or low-friction sliders that keep the robot horizontal. If both the wheels are driven in the same direction and speed, the robot will go in a straight line.</p> <p></p> <p>If both wheels are turned with equal speed in opposite directions, as is clear from the diagram shown, the robot will rotate about the central point of the axis. Otherwise, depending on the speed of rotation and its direction, the center of rotation may fall anywhere on the line defined by the two contact points of the tires.</p> <p></p> <p>Let the distance between the driven wheels be \\(2d\\) and choose the \\((x,y)\\) reference point halfway between the wheels. Writing the configuration as \\(q = (\\phi,x,y,\\theta_L,\\theta_R)\\), where \\(\\theta_L\\) and \\(\\theta_R\\) are the rolling angles of the left and right wheels, respectively, the kinematic equations are</p> \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta_L}\\\\ \\dot{\\theta_R} \\end{bmatrix} = \\begin{bmatrix} -r/2d &amp; r/2d\\\\ \\frac{r}{2}cos\\phi &amp; \\frac{r}{2}cos\\phi\\\\ \\frac{r}{2}sin\\phi &amp; \\frac{r}{2}sin\\phi\\\\ 1 &amp; 0\\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} u_L\\\\ u_R \\end{bmatrix} \\] <p>where \\(u_L\\) is the angular speed of the left wheel and \\(u_R\\) that of the right. A positive angular speed of each wheel corresponds to forward motion at that wheel.</p> <p>While we can vary the velocity of each wheel, for the robot to perform rolling motion, the robot must rotate about a point that lies along their common left and right wheel axis. The point that the robot rotates about is known as the ICC - Instantaneous Center of Curvature.</p> <p>By varying the linear velocity of the wheels \\(V_R\\) and \\(V_L\\), we can vary the radius of curvature \\(R\\) that the robot follows. Because the rate of rotation \\(\\omega\\) about the ICC must be the same for both wheels, we can write the following equations</p> \\[ \\omega(R + d) = V_R\\]  \\[\\omega(R - d) = V_L \\] <p>A differential drive robot cannot move in the direction along the axis - this is a singularity. Differential drive vehicles are very sensitive to slight changes in velocity in each of the wheels. Small errors in the relative velocities between the wheels can affect the robot trajectory.</p>"},{"location":"mechanical/drive_mechanism/#ackermann-steering","title":"Ackermann Steering","text":"<p>Drawbacks of the differential drive are its reliance on a caster wheel, which performs poorly at high speeds, and difficulties in driving straight lines as this requires both motors to drive at the exact same speed. These drawbacks are mitigated by car-like mechanisms, which are driven by a single motor and can steer their front wheels. This mechanism is known as Ackermann steering.</p> <p></p> <p>To define the configuration of the car, we ignore the rolling angles of the four wheels and write \\(q = (\\phi,x,y,\\psi)\\), where \\((x,y)\\) is the location of the midpoint between the rear wheels, \\(\\phi\\) is the car\u2019s heading direction, and \\(\\psi\\) is the steering angle of the car, defined at a virtual wheel at the midpoint between the front wheels. The controls are the forward speed \\(v\\) of the car at its reference point and the angular speed \\(\\omega\\) of the steering angle. The car\u2019s kinematics are</p> \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\psi} \\end{bmatrix} = \\begin{bmatrix} (tan\\psi)/l &amp; 0\\\\ cos\\phi &amp; 0\\\\ sin\\phi &amp; 0\\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} v\\\\ \\omega \\end{bmatrix} \\] <p>Disadvantages Of Ackermann Steering : The turning mechanism must be accurately controlled. A slight inaccuracy may cause large odometry errors The system is Non \u2013 Holonomic hence path planning is extremely difficult as well as inaccurate There are no direct directional actuators.</p>"},{"location":"mechanical/drive_mechanism/#other-type-of-drive-mechanism","title":"Other type of Drive Mechanism","text":"<p>There are many different ways in which a robot can be modelled and controlled, some other drive mechanism used in various systems are</p> <ul> <li> <p>Skid Steering - The left and right wheels are driven independently. Steering is accomplished by actuating each side at a different rate or in a different direction, causing the wheels or tracks to slip, or skid, on the ground. The wheels typically have no separate steering mechanism and hold a fixed straight alignment on the body of the machine. By turning the left and right wheel pairs at different speeds, the machine turns by skidding, or dragging its fixed-orientation wheels across the ground.</p> </li> <li> <p>Synchronous Drive - This system uses synchronous rotation of its wheels to achieve motion &amp; turns. It is made up of a system of motors. One set of which drive the wheels and the other set turns the wheels in a synchronous fashion The two sets can be directly mechanically coupled as they always move in the same direction with same speed.</p> </li> <li> <p>Articulated Drive - Similar to Ackerman Steering concept, Articulated method drives a robot by deforming the entire chassis or frame to turn instead of just the wheels. This is generally used for industrial robots where a four wheeled robot is split into two, the front part and the rear part which is connected by a vertical hinge. A motor changes the angle of front part of chassis which turns the robot in a required direction and other motor drives it.</p> </li> </ul>"},{"location":"mechanical/drive_mechanism/#references","title":"References","text":"<ol> <li>A 4-wheel omni drive robot - Omnibase developed by ERC, applying the concepts of omnidrive can be found here.</li> <li>For more details on these drive mechanisms refer Chapter 13 of the Modern Robotics - Mechanics, Planning, And Control by Kevin M. Lynch and Frank C. Park, a video playlist of the same can be found here.</li> <li>A video on Differential Drive mechanism from Control of Mobile Robots course by Dr. Magnus Egerstedt can be found here.</li> <li>More information on Designing of Ackermann Steering can be read from this paper.</li> </ol>"},{"location":"mechanical/intro/","title":"Introduction","text":"<p>Mechanical aspects of robotics involve desiging,building and testing mechanical sensors and devices for a robot. </p> <p>This includes the robot configuration, type of robot, joint mechanisms, axes, heat transfer characteristics, mounting positions, among many other aspects that go into the creation of a new robot.  CAD or other design software is used to create a new robot concept and how to best manufacture it. </p> <p>Mechanical design also involves solving the kinematics and dynamics equation of the robot, which are essential for peforming any task with robots.</p>"},{"location":"mechanical/mech101/","title":"Mechanical 101","text":"<p>We conducted a session on the basics of mechanical design and the equipment/components that can be used on collegiate level. The session was conducted by Aasim Sayyed and a documented version of what was taught can be found here</p>"},{"location":"mechanical/position%20and%20orientation/","title":"POSITION AND ORIENATION REPRESENTATION","text":""},{"location":"mechanical/position%20and%20orientation/#position-and-translation","title":"Position and translation","text":"<p>The minimum number of coordinates required to locate a body in Euclidean space is six. A coordinate frame i consists of an origin, denoted \\(O_{i}\\) and a triad of mutually orthogonal basis vectors, denoted \\((\\hat x_{i} \\hat y_{i } \\hat z_{i})\\), that are all fixed within a particular body. The pose of a body will always be expressed relative to some other body, so it can be expressed as the pose of one coordinate frame relative to another. Similarly, rigid-body displacements can be expressed as displacements between two coordinate frames, one of which may be referred to as moving, while the other may be referred to as fixed.</p> <p>The position of the origin of coordinate frame i relative to coordinate frame j can be denoted by the 3 X 1 vector </p> \\[ ^{j} \\textbf {p} _{i} =  \\begin{pmatrix} ^{j} p^{x} _{i} \\\\ ^{j} p^{y} _{i} \\\\ ^{j} p^{z} _{i}   \\end{pmatrix}\\] <p>The components of this vector are the Cartesian coordinates of \\(O_{i}\\) in the j frame, which are the projections of the vector  \\(^{j} \\textbf {p} _{i}\\)  onto the corresponding axes.</p>"},{"location":"mechanical/position%20and%20orientation/#orientation-and-rotation","title":"Orientation and Rotation","text":"<p>A rotation is a displacement in which at least one point in the rigid body remains in its initial position and not all lines in the body remain parallel to their initial orientations. The orientation of coordinate frame i relative to coordinate frame j can be denoted by expressing the basis vectors .\\(( \\hat x_{i} \\hat y_{i} \\hat z_{i})\\) in terms of the basis vectors ,\\(( \\hat x_{j} \\hat y_{j} \\hat z_{j})\\).This yields, \\(( ^{j}\\hat x_{i} ^{j}\\hat y_{i} ^{j}\\hat z_{i})\\)  which when written together as a  3X3 matrix is known as the rotation matrix. The components of \\(^{j}R_{i}\\) are the dot products of the basis vectors of the two coordinate frames.</p> <p>\\(^{j}R_{i}\\) = \\(\\begin{pmatrix} \\hat x _{i}.\\hat x _{j} &amp;  \\hat y _{i}.\\hat x _{j} &amp;  \\hat z _{i}.\\hat x _{j} \\\\  \\hat x _{i}.\\hat y _{j} &amp;  \\hat y _{i}.\\hat y _{j} &amp;  \\hat z _{i}.\\hat y _{j}  \\\\  \\hat x _{i}.\\hat z _{j} &amp;  \\hat y _{i}.\\hat z _{j} &amp;  \\hat z _{i}.\\hat z _{j} \\end{pmatrix}\\)</p> <p>Because the basis vectors are unit vectors and the dot product of any two unit vectors is the cosine of the angle between them, the components are commonly referred to as direction cosines. An elementary rotation of frame i about the \\(z_{j}\\) axis through an angle \\(\\theta\\) is</p> <p>\\(R_{z}(\\theta) = \\begin{pmatrix} \\cos(\\theta) &amp; -\\sin(\\theta) &amp; 0\\\\ \\sin(\\theta) &amp; \\cos(\\theta) &amp; 0\\\\ 0 &amp; 0 &amp; 1\\end{pmatrix}\\)</p> <p>while the same rotation about \\(\\hat y_{j}\\) axis is</p> <p>\\(R_{Y}(\\theta) = \\begin{pmatrix} \\cos(\\theta) &amp; 0 &amp; \\sin(\\theta)\\\\ 0 &amp; 1 &amp; 0\\\\ -\\sin(\\theta) &amp; 0 &amp; \\cos(\\theta)\\end{pmatrix}\\)</p> <p>and about the  axis \\(\\hat x_{j}\\) is</p> <p>\\(R_{X}(\\theta) = \\begin{pmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; \\cos(\\theta) &amp; -\\sin(\\theta)\\\\ 0 &amp; \\sin(\\theta) &amp; \\cos(\\theta)\\end{pmatrix}\\)</p> <p>Rotation matrices are combined through simple matrix multiplication such that the orientation of frame i relative to frame k can be expressed as</p> <p>\\(^{k}R_{i} = ^{k}R_{j} ^{j}R_{i}\\)</p>"},{"location":"mechanical/position%20and%20orientation/#euler-angles","title":"Euler Angles","text":"<p>For a minimal representation, the orientation of coordinate frame i relative to coordinate frame j can be denoted as a vector of three angles \\((\\alpha , \\beta , \\gamma)^{T}\\). These angles are known as Euler angles when each represents a rotation about an axis of a moving coordinate frame. In this way, the location of the axis of each successive rotation depends upon the preceding rotation(s), so the order of the rotations must accompany the three angles to define the orientation.</p> <p>There are many other representations for orientation such as Fixed-Angles, Quaternions and Angle-Axis.</p>"},{"location":"mechanical/position%20and%20orientation/#homogeneous-transformations","title":"Homogeneous Transformations","text":"<p>With homogeneous transformations, position vectors and rotation matrices are combined together in a compact notation. Any vector \\(^{i}r\\) expressed relative to the i coordinate frame can be expressed relative to the j coordinate frame if the position and orientation of the i frame are known relative to the j frame.</p> <p>\\(^{j}r = ^{j}R_{i} ^{i}r +  ^{j}p_{i}\\)</p> <p>where \\(^{j}p_{i}\\) is the position of the origin of coordinate frame i relative to coordinate frame j and  \\(^{j}R_{i}\\) is the orientation of frame i relative to frame j .</p> <p>The above equation can be written as</p> <p>\\(\\begin{pmatrix} ^{j}r \\\\ 1 \\end{pmatrix}\\) = \\(\\begin{pmatrix}  ^{j}R_{i}  &amp;  ^{j}p_{i}\\\\ 0^{T} &amp; 1 \\end{pmatrix}\\begin{pmatrix} ^{i}r \\\\ 1 \\end{pmatrix}\\)</p> <p>where</p> <p>\\(^{j}T_{i} = \\begin{pmatrix}  ^{j}R_{i}  &amp;  ^{j}p_{i}\\\\ 0^{T} &amp; 1 \\end{pmatrix}\\)</p> <p>is the 4X4 homogeneous transformation matrix . Just like Rotation matrices, homogeneous transformation matrices can also be transformed using matrix cross-multiplication.</p> <p>\\(^{k}T_{i} = ^{k}T_{j} ^{j}T_{i}\\)</p>"},{"location":"simulation/intro/","title":"Introduction","text":"<p>Simulation is an essential part of Robotics Automation. They provide a versatile platform to quickly test your code for bugs and performance and try out new ideas. While robots are becoming more accessible all the time, it is still not at the stage where you can test your code directly on them. In fact, running code in simulations will always be more convenient. For a more thorough introduction on simulators and the robots you can find in them, go through Chapter 6 of Morgan Quigley.</p>"},{"location":"simulation/gazebo/Robot_Description/","title":"Introduction:","text":"<p>Robot models in gazebo serve as the digital counterparts of physical robots, representing their physical characteristics, kinematics, dynamics, and sensors in a virtual setting. These models play a crucial role in various fields, including robotics research, autonomous systems development, and even educational purposes. Using Robot Description Formats, roboticists can rapidly prototype and experiment with various robotic configurations without the need for a physical robot. This capability significantly speeds up the development process, allowing for iterative testing, debugging, and fine-tuning of robot designs and control algorithms before deployment on real hardware.</p>"},{"location":"simulation/gazebo/Robot_Description/#model","title":"Model:","text":""},{"location":"simulation/gazebo/Robot_Description/#urdf","title":"URDF:","text":"<p>In Gazebo, URDF files serve as the foundation for creating robot models. A URDF file contains essential information about the robot\u2019s mechanical structure, such as links, joints, sensors, and physical properties like mass, inertia, and collision geometry. Additionally, it can define visual elements, enabling users to visualize the robot accurately during simulations. These description files require designs of various components of the robot, hence are usually bundled with a meshes folder having an accessible path. The model files are of the XML format and have the extension <code>.urdf</code>; however, if you use macros to clean up the code, it becomes <code>urdf.xacro</code>. Refer to roswiki for more on urdfs. There are plugins in various 3d modelling softwares that automatically generate urdfs. It can also be done manually. (Using the urdf snippet tool in vscode fast-tracks the process of writing urdfs). Following tutorials would help gain better understanding of its structure, which is imperative for tweaking attributes and on the go customisation. Sometimes, running a software like Gazebo just for visualisation becomes tedious use the URDF previewer that is conveniently part of the ROS extension in Visual Studio Code.</p>"},{"location":"simulation/gazebo/Robot_Description/#methods-of-spawning","title":"Methods of spawning:","text":""},{"location":"simulation/gazebo/Robot_Description/#writing-a-simulation-description-format-sdf-file","title":"Writing a simulation description format (SDF) file:","text":"<ul> <li>Create a config file.</li> <li>Including meshes(stl,dae) in .sdf file.</li> </ul>"},{"location":"simulation/gazebo/Robot_Description/#importing-using-gazebo-gui","title":"Importing using gazebo GUI:","text":"<pre><code>In gazebo, navigate to insert/path look for the mesh(.stl;.dae) file and add its path. The model can be dragged directly into the scene and can further be reloaded using the saved world file.\n</code></pre>"},{"location":"simulation/gazebo/Robot_Description/#spawnurdf-in-the-launch-file","title":"Spawn.urdf in the launch file:","text":"<ul> <li>Call the spawn.urdf method of the ros_gazebo node from the ros_gazebo package <code>xml &lt;node name=\"spawn_model\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-urdf -model urdf_assembly6 -param robot_description -z 1.0\" output=\"screen\" /&gt; &lt;!--    model name          urdf          position--&gt;</code></li> <li>Position the urdf in 3d space (0 0 1.0)</li> </ul>"},{"location":"simulation/gazebo/Robot_Description/#control","title":"Control:","text":"<p>When urdfs are simply spawned into an environment, the joints go limp under the influence of gravity. ROS (Robot Operating System) Controllers help maintaining a joint state or position and play a fundamental role in controlling robotic systems within the ROS ecosystem. To effectively interact with and control robots, ROS Controllers are employed to handle various aspects of robot behaviour, such as motion control, joint control etc. The primary objective of ROS Controllers is to abstract the complexities of low-level hardware control and provide a unified interface for developers to command and manage robots. This abstraction allows robot designers and developers to focus on higher-level tasks and algorithms without having to deal with specific hardware details.</p> <pre><code>&lt;node name=\"controller_spawner\" pkg=\"controller_manager\" type=\"spawner\" respawn=\"false\"\noutput=\"screen\" ns=\"/manipulator\" args=\"joint1_position_controller joint2_position_controller joint3_position_controller joint_state_controller\"/&gt;\n```\n\n**Joint State Controller**: The joint state controller is a special type of controller that reads joint states (position, velocity, effort) from the robot's sensors and publishes them to the ROS network. This controller is essential for other controllers that require feedback about the robot's current state.\n\n**ROS Messages and Services**: ROS Controllers utilize ROS messages and services to receive commands and send feedback to other ROS nodes. This communication mechanism ensures seamless integration with the broader ROS ecosystem.\n</code></pre>"},{"location":"simulation/gazebo/Robot_Description/#key-components-of-ros-controllers","title":"Key Components of ROS Controllers:","text":"<ul> <li>Hardware Interface: The hardware interface is a crucial component of ROS Controllers, responsible for communication between the higher-level control system (software) and the robot\u2019s actuators (hardware). This needs to be added in the description file under the transmission tag:     <code>xml        \u2018\u2019&lt;transmission name=\"simple_trans\"&gt;         &lt;type&gt;transmission_interface/SimpleTransmission&lt;/type&gt;         &lt;joint name=\"foo_joint\"&gt;         &lt;hardwareInterface&gt;EffortJointInterface&lt;/hardwareInterface&gt;         &lt;/joint&gt;\u2019\u2019</code> Refer to transmission elements.</li> <li>Controller Plugins: Controller plugins are modular software components that implement different control algorithms and strategies. These plugins receive high-level commands from the user or other ROS nodes and translate them into low-level control signals that the hardware can understand. Some commonly used controller plugins include joint position controllers, joint velocity controllers, and effort controllers.</li> </ul> <p>Controller Manager: The controller manager is responsible for loading and unloading controller plugins and managing their lifecycle. It provides a centralized interface for activating and deactivating controllers based on user commands or the current robot state. It is loaded into the launch file as a rosparam and is a config file in nature with the extension <code>.yaml</code>. ```xml   </p> <p></p>"},{"location":"simulation/gazebo/Robot_Description/#types-of-ros-controllers","title":"Types of ROS Controllers:","text":"<ul> <li> <p>Position Controllers: Position controllers are used to set the desired joint positions of a robot. They compute the necessary control efforts to reach and maintain these positions.</p> </li> <li> <p>Velocity Controllers: Velocity controllers command the desired joint velocities of a robot. They regulate the joint speeds to achieve the desired motion.</p> </li> <li> <p>Effort Controllers: Effort controllers apply specific forces or torques to robot joints, allowing for precise control of joint efforts. This type of control is particularly useful for applications requiring high accuracy and force/torque control.</p> </li> <li> <p>Trajectory Controllers: Trajectory controllers enable robots to follow predefined trajectories, smoothly interpolating between waypoints.</p> </li> </ul>"},{"location":"simulation/gazebo/Robot_Description/#glossary","title":"Glossary:","text":"<ul> <li>Urdfs(Universal Robot Description Format)-an xml format defining the attributes(inertial,visual) of a single robot. </li> <li>Meshes- models created using interconnected polygons to create a visual and geometric representation of the robot\u2019s structure</li> <li>SDF(simulation Description Format)- t is an XML-based file format used to describe the world, objects, and entities in a simulated environment within the Gazebo robotics simulator.</li> <li>Xacro-an xml format used to clean up urdfs by handling repetitive code blocks or macros.</li> <li>Transmission tags- An extension to the URDF robot description model that is used to describe the relationship between an actuator and a joint.</li> </ul>"},{"location":"simulation/gazebo/basics/","title":"Gazebo","text":"<p>Gazebo is the most popular physics simulator for robotics development. It can simulate robots in a 3D environment and can be fully integrated into ROS integrated with Gazebo using the gazebo_ros ROS package. You can interface your robots in the simulation using ROS and control them using ROS messages and services.</p>"},{"location":"simulation/gazebo/basics/#21-installation","title":"2.1 Installation","text":"<p>Gazebo and gazebo_ros package are both automatically installed when you install ROS. To make sure you have all the ROS packages necessary for running Gazebo simulations are installed</p> <p><code>sudo apt-get install ros-melodic-gazebo-*</code></p> <p>Gazebo can also be installed independently of ROS by using the command</p> <p><code>curl -sSL http://get.gazebosim.org | sh</code></p> <p>in the terminal for Ubuntu. Alternative methods of installing gazebo and installation guides for installling gazebo on other operating systems can be found here.</p>"},{"location":"simulation/gazebo/basics/#22-getting-started","title":"2.2 Getting Started","text":"<p>You can launch the Gazebo GUI simulator window by just running the command <code>gazebo</code> in the terminal. To understand how to spawn robot models in gazebo it is recommended to first get familiar with .urdf, .sdf and .world files. You can refer to the Robot Description section to read about these.</p> <p>A file can be opened simply by running the follwing command in the command line:</p> <p><code>gazebo &lt;path/to/file&gt;</code></p>"},{"location":"simulation/gazebo/basics/#23-client-server-separation","title":"2.3 Client Server Separation","text":"<p>Running the <code>gazebo</code> command starts two programmes, namely the gzserver and the gzclient. The gzserver is responsible for doing most of the \u2018processing\u2019 part, i.e., doing all the calculations for the simulation, sensor data generation, basically all the backend processing. The gzclient is responsible for generating the user interface. It provides a nice visualization of simulation, and convenient controls over various simulation properties. gzserver is capable of running independently of gzclient and vice-versa. For eg; in many cases gzserver is run on a cloud computer in case enough processing power is not available locally. Try running the command <code>gzserver</code> in one terminal and the command <code>gzclient</code> in other terminal. You will notice that the gazebo window pops up only when you run the <code>gzclient</code> command. The term run headless is used to refer to cases when only the gzserver is being used.</p>"},{"location":"simulation/gazebo/basics/#24-environment-variables-in-gazebo","title":"2.4 Environment Variables in Gazebo","text":"<p>Environment Variables are variables whose values are valid throughout the system and are used by different applications and the OS for several purposes. These environment variables can contain different types of things ranging from parameter values to paths to certain files depending on what they are used for. Gazebo uses various such environment variables too. These variables and their uses are described below:</p> <ul> <li>GAZEBO_MODEL_PATH : This environment variable contains colon-separated paths to different directories where gazebo will search for models. Models refers to the sdf file describing the robot. For more information on this refer to the Robot Description section of the handbook.   \u00a0</li> <li>GAZEBO_RESOURCE_PATH: This environment variable contains colon-separated set of directories where Gazebo will search for other resources such as world and media files. For eg. if you run the command <code>gazebo worlds/pioneer2dx.world</code>. You will see gazebo window pop up with an empty environment. In fact you can execute this command in any directory. You might ask how does gazebo know where the <code>worlds</code>  directory is stored?. The answer is that the path to the world directory, that is <code>/usr/share/gazebo-7/worlds</code> is stored in the environment variable <code>GAZEBO_RESOURCE_PATH</code>. \u00a0</li> <li>GAZEBO_MASTER__URI: URI of the Gazebo master. This specifies the IP and port where the server(gzserver) will be started and tells the clients(gzclients) where to connect to. \u00a0</li> <li>GAZEBO_PLUGIN_PATH: colon-separated set of directories where Gazebo will search for the plugin shared libraries at runtime. Plugins are basically..... You can refer to this section to read more about gazebo plugins. \u00a0</li> <li>GAZEBO_MODEL_DATABASE_URI: URI of the online model database where Gazebo will download models from.</li> </ul> <p>The default values of these environment variables are stored in the <code>&lt;install_path&gt;/share/gazebo/setup.sh</code> file. If you want to change the values of this variables for example, add or remove a path from <code>GITHUB_MODEL_PATH</code> you will have to source this file first using the command</p> <p><code>source &lt;install_path&gt;/share/gazebo/setup.sh</code></p> <p>Once this is done you can edit that value of the variable by editing the value by opening the <code>setup.sh</code> file or directly thorugh the terminal/command line using the command:</p> <p><code>GITHUB_MODEL_PATH=$GITHUB_MODEL_PATH:&lt;path of the directory you want to add&gt;</code></p>"},{"location":"simulation/stdr/Basics/","title":"Basics of STDR","text":""},{"location":"simulation/stdr/Basics/#general-introduction","title":"General Introduction","text":"<p>STDR is a simple two dimensional robot simulator. It is very useful in cases where there is no need for computationally costly 3-D simulation of robots. It is computationally light and serves the purpose good. Hence it is very useful for learning based robotics or for multi robot simulation.</p>"},{"location":"simulation/stdr/Basics/#installation","title":"Installation","text":"<ol> <li>For ROS Kinetic, stdr can be installed using apt-get.</li> <li>For ROS Melodic, it is advisible to install stdr from source.</li> </ol>"},{"location":"simulation/stdr/Basics/#architecture-overview","title":"Architecture Overview","text":"<p>(Reference: ROS Wiki)</p>"},{"location":"simulation/stdr/Basics/#basic-usage","title":"Basic Usage","text":"<ul> <li>The <code>stdr_launchers</code> package contains launch files basic usage. However, custom launch files can be created to serve personal purposes easily. Some of the launch files are<ol> <li><code>server_no_map.launch</code> launches the stdr server without any map, robot or the gui.</li> <li><code>server_with_map_and_gui.launch</code> launches the serve with preloaded map and gui.</li> <li><code>server_with_map_and_gui_plus_robot.launch</code> launches the stdr_server, with preloaded map and robot along with the gui</li> </ol> </li> <li>You can also launch Rviz with a preset config file using <code>rviz.launch</code> file in the stdr_launchers package.</li> </ul>"},{"location":"simulation/stdr/Basics/#robot-namespaces","title":"Robot Namespaces","text":"<ol> <li>The topics corresponding to each robot have a unique namespace attached to it. For example the first robot launched has a namespace <code>/robot0</code>. Published topics pertaining to that robot are published as <code>/robot0/topic_name</code>.</li> <li>Note that whenever a new robot is spawned the robot number is incremented by 1. This happens even though you delete a robot.</li> <li>such namespacing avoids conflicts of topic names when doing multi robot simulation.</li> </ol>"},{"location":"simulation/stdr/Basics/#references","title":"References","text":"<ol> <li>For more information refer the <code>stdr_simulator</code> page  in ROS Wiki.</li> <li>The github repository for stdr_simulator.</li> </ol>"}]}